# 16-神经网络的基本骨架-nn.Module的使用

打开pytorch官网，在左边可以看到Python API，也就是前面提到的包（可以理解为工具），我们今天学的就是torch.nn(nn是Neural Network的缩写)

![image-20251026153156489](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261531649.png)

- container：容器，可以理解为神经网络的骨架（定义一些结构），只需要往结构里加入一些内容就可以组成神经网络（本节课将学习骨架搭建）

  - 最常用的是Module，为所有神经网络提供基类（骨架/模板，对模板不满意的内容进行修改，如下下图的`__init__` & `forward`），你的模型必须继承在Module类下面（Module是父类）

    ![image-20251026153552562](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261535655.png)

    ![image-20251026153629787](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261536879.png)

    - 初始化过程要先调用父类的初始化函数`super(Model, self).__init__()`

      - self：指Model这个类

    - 神经网络框架和计算流程

      - 前向传播：input经过forward计算进行输出output

        ![image-20251026154010362](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261542793.png)

        - x先经过卷积conv1，在经过非线性层relu【max(0, x)】,再经过一次卷积conv2，最后经历理一次非线性层relu【max(0, x)】

          ![image-20251026154318785](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261543863.png)

    - forward源码

      - 每次调用会定义计算图，应该在每个子类中进行重写

        ![image-20251026154436480](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261544550.png)

  - container以外的东西都是往结构里填充的东西

- Convolution Layers: 卷积层

- Pooling Layer:池化层

- Non-linear Activations:非线性激活

在pycahrm项目中新建python文件nn_module

```python
from torch import nn
class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()# 会自动补全
 
```

```python
from torch import nn
import torch

class Tudui(nn.Module):
    # 另一种方法：利用pycharm的选项卡：点击code菜单栏下的Generate，在弹出的页面中选择Override Methods，选择第一个__init__,代码自动补全
    def __init__(self):
    	super().__init__()
    
    def forward(self, input):
        output = input + 1
        return output
    
tudui = Tudui()
x = torch.tensor(1.0)
output = tudui(x)
print(output)
# tensor(2.)
    
```

调用实例对象加（）之所以会调用forward（）方法是因为：首先调用父类的`__call__`方法，父类中该方法调用了forward（）方法，而子类重写了该方法，所以最终调用到了子类的forward方法

![image-20251026161140649](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261611701.png)

![image-20251026161244660](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261612755.png)

![image-20251026161325694](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261613779.png)

## 16.2-super()方法

### 概述

super() 是python 中调用父类（超类）的一种方法，在子类中可以通过super()方法来调用父类的方法。【超类： 是指 2层以上的继承关系，假如 C类继承B类，B类由继承A类，那么A类就是C类的超类】

**作用：**

- 在继承中，让代码维护更加简单
- 解决多继承带来的重复调用（菱形继承）、查找顺序（MRO）问题

**语法：**

```python
super(type[, object-or-type])
```

> 参数：
> type – 类。
> object-or-type – 类，一般是 self

Python 3 和 Python 2 的另一个区别是: **Python 3 可以使用直接使用 super().xxx 代替 super(Class, self).xxx :**

### 16.2.1-super的使用

**1.通过super() 来调用父类的__init__ 构造方法：**

```python
class Person():
      def __init__(self):
    　　　　print('我是Peson的__init__构造方法')

class Student(Person):
        def __init__（self）:
    　　　　　super().__init__()
   　　　　　  print（'我是Student的__init__构造方法')

stu = Student()
-----------------------------------------
我是Peson的__init__构造方法
我是Student的__init__构造方法
```

**2 通过supper() 来调用与子类同名的父类方法**
**2.1 单继承**
在单继承中 super 就像大家所想的那样，主要是用来调用父类的方法的。

```python
class A:
    def __init__(self):
        self.n = 2

    def add(self, m):
        print('self is {0} @A.add'.format(self))
        self.n += m

class B(A):
    def __init__(self):
        self.n = 3

    def add(self, m):
        print('self is {0} @B.add'.format(self))
        super().add(m)
        self.n += 3
b = B()
b.add(2)
print(b.n)
```

我们执行以上代码，得到的输出如下：

```python
self is <__main__.B object at 0x106c49b38> @B.add
self is <__main__.B object at 0x106c49b38> @A.add
8
```

这个结果说明了两个问题:

> 1、super().add(m) 确实调用了父类 A 的 add 方法。
> 2、super().add(m) 调用父类方法 def add(self, m) 时, **此时父类中 self 并不是父类的实例而是子类的实例**, 所以 b.add(2) 之后的结果是 5 而不是 4 。

### 16.2.2-MRO：方法搜索顺序

- MRO是method resolution order,主要用于在对继承是判断方法、属性的调用路径【顺序】，其实也就是继承父类方法时的顺序表。
- Python中针对类提供了一个内置属性__mro__可以查看方法的搜索顺序

```python
class C(A,B):
	pass
print(C.__mro__)
out:
(<class '__main__.C'>,<class'__main__.A'>,<class'__main__B'>,<class 'object'>)
```

在搜索方法时，是按照__mro__的输出结果从左到右的顺序查找的

- 如果当前类中找到方法，就直接执行，不再搜索
- 如果没有找到，就查找下一个类中是否有对应的方法，如果找到，就直接执行，不再搜索
- 如果找到最后一个类，还是没有找到方法，程序报错

**2.2 多继承**
在多继承中，会涉及到一个MRO(继承父类方法时的顺序表) 的调用排序问题。即严格按照MRO 顺序执行super方法

```python
class A:
    def __init__(self):
        self.n = 2

    def add(self, m):
        print('self is {0} @A.add'.format(self))
        self.n += m

class B(A):
    def __init__(self):
        self.n = 3

    def add(self, m):
        print('self is {0} @B.add'.format(self))
        super().add(m)
        self.n += 3

class C(A):
    def __init__(self):
        self.n = 4

    def add(self, m):
        print('self is {0} @C.add'.format(self))
        super().add(m)
        self.n += 4

class D(B, C):
    def __init__(self):
        self.n = 5

    def add(self, m):
        print('self is {0} @D.add'.format(self))
        super().add(m)
        self.n += 5

d = D()
d.add(2)
print(d.n)
out:
self is <__main__.D object at 0x10ce10e48> @D.add
self is <__main__.D object at 0x10ce10e48> @B.add
self is <__main__.D object at 0x10ce10e48> @C.add
self is <__main__.D object at 0x10ce10e48> @A.add
19
```

- 同样，不管往上调用几次，调用父类方法中 self 并不是父类的实例而是子类的实例，在上例中都是D的实例化对象
- D.mro() == [D,B, C, A, object] ，多继承的执行顺序会严格按照mro的顺序执行。
- 整体的调用流程图如下：

```python
d = D()
d.n == 5
d.add(2)

class D(B, C):          class B(A):            class C(A):             class A:
    def add(self, m):       def add(self, m):      def add(self, m):       def add(self, m):
        super().add(m)  1.--->  super().add(m) 2.--->  super().add(m)  3.--->  self.n += m
        self.n += 5   <------6. self.n += 3    <----5. self.n += 4     <----4. <--|
        (14+5=19)               (11+3=14)              (7+4=11)                (5+2=7)
```

![在这里插入图片描述](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261634657.png)
**其它：**
1.super().__init__相对于类名.**init**，在单继承上用法基本无差别
2.但在多继承上有区别，super方法能保证每个父类的方法只会执行一次，而使用类名的方法会导致方法被执行多次。
3.多继承时，使用super方法，对父类的传参数，应该是由于python中super的算法导致的原因，必须把参数全部传递，否则会报错
4.单继承时，使用super方法，则不能全部传递，只能传父类方法所需的参数，否则会报错

# 17-卷积操作

> 卷积相当于一个饼, 盖在上面,做运算

![image-20251026171554706](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261715853.png)

- 1d: 1维卷积神经网络
- 2d: 2维卷积神经网络（比如图像），主要对2d进行讲解



**torch.nn** VS **torch.nn.functional**

- troch.nn是对 torch.functional的封装，更加利于我们使用
- torch.nn.functional使用起来更麻烦,里面的函数跟torch.nn是对应的关系

![image-20251026172147569](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261721703.png)

来看torch.nn.functional下的conv2d

![image-20251026172233327](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261722470.png)

- input：输入，格式为（minibatch， 通道数，长，宽）
- weight：权重，可以看成卷积核，格式为（ 输出通道数，其他计算【groups一般取为1， group是分组卷积，对不同的通道使用不同的卷积核】，长，宽）
- bias：偏置
- stride：步进
- padding:在图像的左右两边进行填充，取值可以为一个数或者元组【长，宽】，默认值为0（不进行填充）



![image-20251026172551510](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261725613.png)

- 左边是5*5大小的图像，每个数字代表在该个像素中颜色显示

- 卷积核：3*3大小的

- 卷积过程：先将卷积核与图像左上角进行匹配，对应位置相乘再最后求和，该位置的结果是$1*1+2*2+0*1+0*0+1*1+2*0+1*2+2*1+1*0=10$，将其进行输出

  ![image-20251026172725204](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261727280.png)

  - 接下里需要将卷积核向右整体移动一格（sride=1）,该位置的结果是$2*1+0*2+3*1+1*0+2*1+3*0+2*2+1*1+1*0=12$,将12进行输出

    ![image-20251026172950138](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261729222.png)

  - 接下里需要将卷积核向右整体移动一格（sride=1）,该位置的结果是$0*1+3*2+1*1+2*0+3*1+1*0+1*2+0*1+0*0=12$,将12进行输出

    ![image-20251026173121336](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261731433.png)

  此时与图像右边缘重合，右边无法移动，此时需要向下换一行从左边还是进行匹配

  > ![image-20251026173510342](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261735413.png)
  >
  > - sH：控制横向的步进（默认为1）
  > - sW：控制纵向的步进（默认为1）

  - 该位置的结果是$0*1+1*2+2*1+1*0+2*1+1*0+5*2+2*1+3*0=18$

    ![image-20251026173646307](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261736395.png)

  - 继续向右滑动一块，该位置的结果$1*1+2*2+3*1+2*0+1*1+0*0+2*2+3*1+1*0=16$

    ![image-20251026173848879](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261738989.png)

  - 继续向右滑动一块，该位置的结果$2*1+3*2+1*1+1*0+0*1+0*0+3*2+1*1+1*0=16$

    ![image-20251026173919833](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261739924.png)

  - 此时与图像右边缘重合，右边无法移动，此时需要向下换一行从左边还是进行匹配

  - 该位置的结果$1*1+2*2+1*1+5*0+2*1+3*0+2*2+1*1+1*0=13$

    ![image-20251026174014134](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261740227.png)

  - 继续向右滑动一块，该位置的结果$2*1+1*2+0*1+2*0+3*1+1*0+1*2+0*1+1*0=9$

    ![image-20251026174130530](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261741641.png)

  - 继续向右滑动一块，该位置的结果$1*1+0*2+0*1+3*0+1*1+1*0+0*2+1*1+1*0=3$

    ![image-20251026174235360](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261742475.png)

  - 卷积后的输出结果（stride=1）

    ![image-20251026180222915](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261802020.png)

    > 当stride=2时，输出为2*2的矩阵

```python
# 验证上面的推导是否准确
import torch
import torch.nn.functional as F

input = torch.tensor([[1, 2, 0, 3, 1],
                     [0, 1, 2, 3, 1],
                     [1, 2, 1, 0, 0],
                     [5, 2, 3, 1, 1],
                     [2, 1,0, 1, 1]])# 两个中括号表示2为矩阵
# 卷积核
kernel = torch.tensor([[1, 2, 1],
                     [0, 1, 1],
                     [2, 1, 0]])
print(input.shape)
# torch.Size([5, 5])
# size值不满足说明文档中输入格式：（minibatch，in_channels,iH, iW）
print(kernel.shape)
# torch.Size([3, 3])
# size值不满足说明文档中输出格式：（out_channels，in_channels/groups,kH, kW）
# 需要对其进行转换
input = torch.reshape(input, (1, 1, 5, 5))
"""
第一个1：batchsize=1
第二个1：通道为1
（5，5） ：（长，宽）
"""
kernel = torch.reshape(kernel, (1, 1, 3, 3))
print(input.shape)
# torch.Size([1, 1, 5, 5])
print(kernel.shape)
# torch.Size([1, 1, 3, 3])

output = F.conv2d(input, kernel, stride=1)
print(output)
# 与前面推导结果一致，每一行&每一列相当于移动2次，加上初始位置，所以形状为torch.Size([1, 1, 3, 3])
```

![image-20251026180119549](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261801649.png)

​	

```python
output2 = F.conv2d(input, kernel, stride=2)
print(output2)
# 每一行&每一列相当于移动3次，加上初始位置，所以形状为torch.Size([1, 1, 2, 2])
```

![image-20251026180404541](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261804637.png)

**padding=1**

相当于原图像上下左右边缘均增加一行/一列，填充值默认为0；

![image-20251026180759719](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261807839.png)

卷积过程卷积核从填充后的左上角进行匹配

![image-20251026180812276](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261808408.png)

```python
output3 = F.conv2d(input, kernel, stride=1, padding=1)
print(output3)

```

![image-20251026180920055](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261809155.png)

明显输出尺寸变大了，验证下，第一个格子的计算结果只有中间的$1*1=1$

![image-20251026181031977](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261810100.png)

# 18-卷积层

![image-20251026195623374](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261956594.png)

- in_channels:输入通道数（需要设置，常用）
- out_channels:输出通道数（需要设置，常用）
- kernel_size:卷积核大小，取值可以为int或者tuple类型【不规则形状，比如（1， 2）】（需要设置，常用）
- stride:卷积过程的步进（有默认取值为1，常用）
- padding：对原图像外围要补充几层（有默认取值0，常用）
- dilation：卷积核中元素的距离，不常用（有默认取值）
  - 具体可以看https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md的gif动画展示
- groups:一般为1，如果不为1则代表分组卷积（几乎遇不到）（有默认参数）
- bias：是否需要偏置（有默认参数）
- padding_modr:padding区域填充模式（有默认参数）

![image-20251026200202008](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262002167.png)

解析in_channels & out_channels

如果in_channels=1 且只有1个卷积核，那么out_channel=1

![image-20251026201123872](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262011038.png)

如果in_channels=1 且有2个卷积核，那么out_channel=2。许多算法都是不算增加卷积数来提升算法效果

![image-20251026201436576](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262014746.png)

> 卷积结果不是卷积的结果

在pycahrm项目中新建python文件nn_conv2d

```python
import torch
import torchvision
from torch.utils.data import DataLoader
from torch import nn
from torch.nn import Conv2d
from torch.utils.tensorboard import SummaryWriter

dataset = torchvision.datasets.CIFAR10("./dataset/CIFAR10", train=False, transform=torchvision.tyransforms.Totensor(), download=True)

dataloader = DataLoader(dataset, batch_size=64)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.conv1 = Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)
        # first 3:输入为彩色图像（3通道）
        # 6：out_channel size
        # second 3： kernel size
    def forward(self, x):
        x = self.conv1(x)
        return x
tudui = Tudui()
print(tudui)
# 查看网络结构
"""
Tudui(
(conv1):ConV2d(3, 6, kernel(3, 3), stride(1, 1))
)
"""   
# 会将kernle=1 拆解为（3， 3）
# 会将stride=1 拆解为（1， 1）

# 用tensorboard进行可视化 
writer = SummaryWriter("../logs")
step = 0
for data in dataloader:
    imgs, targets = data
    output = tudui(imgs)
    print(imgs.shape)
    # tensor.Size([64, 3, 32, 32])
    # 对应卷积神经网络的输入数据格式：（minibatch，in_channels,iH, iW）
    print(output.shape)
    # tensor.Size([64, 6, 30, 30]), 这里设置的batch_size=64
    # 由于卷积核是（3， 3）, 所以卷积后的尺寸变为（30，30 ）
    writer.add_images("input", imgs, step)
    writer.add_images("output", output, step)
    step = step + 1 
    
    # 会报错：因为输出图像是6个channel， 但是彩色图像只能显示3个channel,需要对代码进行修改
```

```python
import torch
import torchvision
from torch.utils.data import DataLoader
from torch import nn
from torch.nn import Conv2d
from torch.utils.tensorboard import SummaryWriter

dataset = torchvision.datasets.CIFAR10("./dataset/CIFAR10", train=False, transform=torchvision.tyransforms.Totensor(), download=True)

dataloader = DataLoader(dataset, batch_size=64)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.conv1 = Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)
        # first 3:输入为彩色图像（3通道）
        # 6：out_channel size
        # second 3： kernel size
    def forward(self, x):
        x = self.conv1(x)
        return x
tudui = Tudui()
print(tudui)
# 查看网络结构
"""
Tudui(
(conv1):ConV2d(3, 6, kernel(3, 3), stride(1, 1))
)
"""   
# 会将kernle=1 拆解为（3， 3）
# 会将stride=1 拆解为（1， 1）

# 用tensorboard进行可视化 
writer = SummaryWriter("../logs")
step = 0
for data in dataloader:
    imgs, targets = data
    output = tudui(imgs)
    print(imgs.shape)
    # tensor.Size([64, 3, 32, 32])
    # 对应卷积神经网络的输入数据格式：（minibatch，in_channels,iH, iW）
    print(output.shape)
    # tensor.Size([64, 6, 30, 30]), 这里设置的batch_size=64
    # 目的是提取输入的更多特征。刚开始输入是RGB三个channels，经过6个卷积核之后就提取出了6个特征即channels。
    # 由于卷积核是（3， 3）, 所以卷积后的尺寸变为（30，30 ）
    # 要保证尺寸不变，则需要设置padding的值为2
    writer.add_images("input", imgs, step)
    #  tensor.Size([64, 6, 30, 30]) --> [xxx, 3, 30, 30](增加batchsize)
    torch.reshape(output, (-1, 3, 30, 30))
    writer.add_images("output", output, step)
    step = step + 1 
    
writer.close()
```

可以看到坐标Project页面的logs文件夹里会生成一个新的log文件，然后在Terminal中输入`tensorboard --logdir=logs`,点击显示的端口，可以在显示的页面中看到图片

![image-20251026204739839](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262047073.png)

![image-20251026204756005](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262047376.png)

batchsize从64变为128



输出尺寸计算公式

![image-20251026205225766](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262052901.png)

# 19-池化层：最大池化的使用

![image-20251026205438908](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262054116.png)

- MaxPool： 最大池化，也叫下采样
- maxUnpool:与MaxPool相反，所以叫上采样

![image-20251026213845440](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262138611.png)

![image-20251026213902802](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262139942.png)

- kernel_size: 取最大值的窗口大小，取值可以为int或者tuple（跟卷积层类似）

- stride：步进，取值可以为int或者tuple（横向，纵向），他的默认值跟kernel_size一致

- dilation:如下图蓝色阴影所示蓝色阴影第一行第一个阴影元素和第二个阴影元素中间间隔了一个，也叫空洞卷积（中间有空隔）

  ![image-20251026215000532](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262150661.png)

- return_indices:用的比较少

- ceil_mode: 当为true时，则会采用ceil模式（类似向上取整）而非floor模式（类似向下取整，默认为False）

  ![image-20251026215338300](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262153451.png)

最大池化：将kernel放在对应的图像像素区域上，计算$max(1*a, 2*b, 0*c, 0*d, 1*e, 2*f, 1*g, 2*h, 1*i)$，作为该区域的输出值，假设为2；

![image-20251026215616011](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262156149.png)

然后将池化kernel向右移动3格（要与kernel_size保持一致），而此时发现超出图像边界，此时就需要决定是否要取这6个数的最大值$max(3*a, 1*b, 3*d, 1*e,  0*g, 0*h)$【假设输出值为3】还是放弃，这将由**ceil_mode**来决定（True：保留这6个数）

![image-20251026215906439](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262159572.png)

向下移动3格，并从左边开始池化，而此时发现超出图像边界，此时就需要决定是否要取这6个数的最大值$max(5*a, 2*b, 3*c, 5*d,  1*e, 0*f)$【假设输出值为5】还是放弃，这将由**ceil_mode**来决定（True：保留这6个数）

![image-20251026220226741](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262202888.png)

向右移动3格，而此时发现超出图像边界，此时就需要决定是否要取这4个数的最大值$max(1*a, 1*b, 1*d, 1*e)$【假设输出值为1】还是放弃，这将由**ceil_mode**来决定（True：保留这4个数）

![image-20251026220423311](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262204454.png)

最终ceil_mode=True 和False的区别 

![image-20251026220541014](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262205220.png)

在pycahrm项目下新建python文件nn_maxpool

```python
import torch
from torch im
from torch.nn import MaxPool2d

input = torch.tensor([[1, 2, 0, 3, 1],
                     [0, 1, 2, 3, 1],
                     [1, 2, 1, 0, 0],
                     [5, 2, 3, 1, 1],
                     [2, 1,0, 1, 1]])# 两个中括号表示2为矩阵
input = torch.reshape(input, (-1, 1, 5, 5))
# input_channel=1
print(input.shape)
# torch.Size([1, 1, 5, 5])

class Tudui(nn.Module):
    def __init__():
        super(Tudui, self).__init__()
        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=True)
        
    def forward(self, input):
        output = self.maxpool1(input)
        return output
    
tudui = Tudui()
output = tudui(input)
print(output)
# 可能会报错： "max_pool2d_with_indices_cpu" not implemented for 'Long", 如果input中的元素是整数，不会对其进行池化，需要将其转化为浮点数
```

```python
# ceil_mode=True
import torch
from torch im
from torch.nn import MaxPool2d

input = torch.tensor([[1, 2, 0, 3, 1],
                     [0, 1, 2, 3, 1],
                     [1, 2, 1, 0, 0],
                     [5, 2, 3, 1, 1],
                     [2, 1,0, 1, 1]], dtype=torch.float32)# 两个中括号表示2为矩阵
input = torch.reshape(input, (-1, 1, 5, 5))
# input_channel=1
print(input.shape)
# torch.Size([1, 1, 5, 5])

class Tudui(nn.Module):
    def __init__():
        super(Tudui, self).__init__()
        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=True)
        
    def forward(self, input):
        output = self.maxpool1(input)
        return output
    
tudui = Tudui()
output = tudui(input)
print(output)
```

![image-20251026221607699](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262216836.png)

```python
# ceil_mode=False
import torch
from torch im
from torch.nn import MaxPool2d

input = torch.tensor([[1, 2, 0, 3, 1],
                     [0, 1, 2, 3, 1],
                     [1, 2, 1, 0, 0],
                     [5, 2, 3, 1, 1],
                     [2, 1,0, 1, 1]], dtype=torch.float32)# 两个中括号表示2为矩阵
input = torch.reshape(input, (-1, 1, 5, 5))
# input_channel=1
print(input.shape)
# torch.Size([1, 1, 5, 5])

class Tudui(nn.Module):
    def __init__():
        super(Tudui, self).__init__()
        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=False)
        
    def forward(self, input):
        output = self.maxpool1(input)
        return output
    
tudui = Tudui()
output = tudui(input)
print(output)
```

![image-20251026221649262](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262216394.png)

**最大池化的作用**

保留输入的特征，同时将数据量减小（5 * 5 ---> 2*2 / 1 * 1，可以想象成1080p视频变为720p，也不影响视频传达信息内容的质量， 但视频大小会减小很多）,训练数据少了，对整个网络来说参数减少了，训练速度也就增快了

```python
# 可视化
import torch
import torchvision
from torch im
from torch.nn import MaxPool2d
from torch.utils.data import DataLoader

dataset = torchvision.datasets.CIFAR10("./dataset/CIFAR10", train=False, download=True, transform=torchvision.transforms.ToTensor())
datalaoder = DataLoader(dataset, batch_size=64)


class Tudui(nn.Module):
    def __init__():
        super(Tudui, self).__init__()
        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=False)
        
    def forward(self, input):
        output = self.maxpool1(input)
        return output
    
tudui = Tudui()

writer = SummaryWriter("logs_maxpool")
step = 0
for data in datalaoder:
    imgs, target = data
    writer.add_images("input", imgs, step)
    output = tudui(imgs)
    # 池化不会有多个channel，输入图像channel为3，池化后输出图像仍然是3维的
    writer.add_images("output", output, step)
    step = step + 1
    
writer.close()
```

在terminal 中输入tensorboard --logdir=logs_maxpool,点击输出的端口，在弹出的网页中可以看到输出结果

![image-20251026223115027](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262231451.png)

![image-20251026223129196](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262231491.png)

大部分的网络都会采用卷积+池化+非线性层

# 20-非线性激活

非线性激活主要是给神经网络引入非线性特性(非线性特征越多，才可以训练出符合各种特征的模型，提高模型泛化能力)，没有激活函数的神经网络实际上是线性可加的（比如前面的池化和卷积，都可以看成是线性回归模型），那么多线性层其实可以归为一层。只具有线性的神经网络表达能力极其有限。常见的右

- RELU(x)=max(0, x)

  - N:batch_size
  - *：可以是任意形状

  ![image-20251026223741097](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262237381.png)

![image-20251026223828135](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262238294.png)

- Sigmoid()函数:会把输入的数值压缩到0和1之间,适合用在二分类任务的输出层。

  ![image-20251026223943437](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262239711.png)

pycharm项目下新建python文件nn_relu

```python
import torch
from torch import nn
from torch.nn import ReLU

input = torch.tensor([[1, -0.5],
                     [-1, 3]])

# 需要指定batch_size
input = torch.reshape(input, (-1, 1, 2, 2))
print(input.shape)
# torch.Size([1, 1, 2, 2])

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.relu1 = ReLU()
        
    def forward(self, input):
        output = self.relu1(input)
        return output
    
tudui = Tudui()
output = tudui(input)
print(output)
```

解释ReLU的参数inplace: 是否就地修改（常用和默认值都是False，防止原始数据被修改和丢失）

![image-20251026224652084](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262246258.png)

上述代码结果：负数都被截断了，用0代替，整数仍然被保留

![image-20251026225015163](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262250308.png)

> ReLU函数对图像的作用不明显，Sigmoid较为明显

```python
import torch
import torchvision
from torch import nn
from torch.nn import ReLU, Sigmoid

input = torch.tensor([[1, -0.5],
                     [-1, 3]])

# 需要指定batch_size
input = torch.reshape(input, (-1, 1, 2, 2))
print(input.shape)
# torch.Size([1, 1, 2, 2])
dataset = torchvision.datasets.CIFAR10("./dataset/CIFAR10", trian=False, download=True， transform=torchvision.transforms.ToTensor())
dataloader = DataLoader(dataset, batch_size=64)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.relu1 = ReLU()
        self.sigmoid1 = Sigmoid()
        
    def forward(self, input):
        output = self.sigmoid1(input)
        return output
    
tudui = Tudui()

step = 0
writer = SummaryWirter("./logs_sigmoid")
for data in dataloder:
    imgs, targets = data
    writer.add_images("input", imgs, step)
    output = tudui(imgs)
    writer.add_images("output", output, step)
    step = step + 1
    
writer.close()
```

在terminal 中输入tensorboard --logdir=logs_sigmoid,点击输出的端口，在弹出的网页中可以看到输出结果

![image-20251026230205939](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262302198.png)

![image-20251026230216048](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262302341.png)

# 21-线形层及其他层价绍

## 21.1-正则化层

采用正则化层（用的比较少）可以提高训练速度

![image-20251027221318916](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272213327.png)

![image-20251027221409560](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272214708.png)

![image-20251027221421592](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272214764.png)

- num_features:前面提到的channel通道数

![image-20251027221542353](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272215519.png)

将输入放入正则化层的网络当中

## 21.2-Recurrent层

主要用于文字识别的网络结构，用的概率不是很多

![image-20251027221756496](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272217679.png)

## 21.3-Transformer层

![image-20251027221823131](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272218313.png)

## 21.4-线性层

![image-20251027221903887](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272219066.png)

![image-20251027221923153](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272219345.png)

![image-20251027222734071](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272227328.png)

上图中每个神经元之间采用线性连接方式，Inpu tLayer --- > Hidden Layer中in_features=d   (包括$x_1,x_2,...,x_d$)，对应的out_features=L(包括$g_1,g_2,...,g_L$)，$g_1$是由$x_1,x_2,...,x_d$计算得到，计算公式是$k_1 * x_1+b_1+k_2*x_2+b_2+...+k_d*x_d+b_d$,神经网络训练主要是对$k_1, k_2, ..., k_d$进行调整

![image-20251027223251961](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272232159.png)

k（权重）和b（偏置）的初始化主要是从均匀分布中进行采样

![image-20251027223448138](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272234307.png)

---

假设有一张5*5图片，将其展成一行，也就是25个，将这25个通过线性层变为3个元素

![image-20251027223833766](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272238935.png)

在pycharm项目下新建python脚本nn_linear

```python
import torchvision

dataset = torchvision.datasets.CIFAR10("./dataset.CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=64, drop_last=true)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.Linear1 = Linear(3072, 10)
        
    def forward(self, input):
        output = self.linear1(input)
        return output
tudui = Tudui()

for data in dataloader:
    img, targets = data
    print(imgs.shape)
    # torch.Size([64, 3, 32, 32])
    # 我们将其拉伸为一维向量
    output = torch.reshape(imgs, (64, 1, 1, -1))
    print(output.shape)
    # torch.Size([64, 1, 1, 3072])
    output = tudui(output)
    print(output.shape)

```



## 21.5-Dropout  层

在训练过程中，会随机将输入tensor的元素变为0，随机的概率为p，防止过拟合

![image-20251027222131151](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272222303.png)

![image-20251027222143514](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272221696.png)

## 21.6-Sparse层

主要用于自然语言处理中

![image-20251027222235084](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272222236.png)

## 21.7-Distance Functions

计算两个值之间的误差

![image-20251027222329845](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272223989.png)

## 21.8-Loss Functions

计算损失函数

![image-20251027222421448](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272224683.png)

......

