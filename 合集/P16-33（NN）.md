# 16-ç¥ç»ç½‘ç»œçš„åŸºæœ¬éª¨æ¶-nn.Moduleçš„ä½¿ç”¨

æ‰“å¼€pytorchå®˜ç½‘ï¼Œåœ¨å·¦è¾¹å¯ä»¥çœ‹åˆ°Python APIï¼Œä¹Ÿå°±æ˜¯å‰é¢æåˆ°çš„åŒ…ï¼ˆå¯ä»¥ç†è§£ä¸ºå·¥å…·ï¼‰ï¼Œæˆ‘ä»¬ä»Šå¤©å­¦çš„å°±æ˜¯torch.nn(nnæ˜¯Neural Networkçš„ç¼©å†™)

![image-20251026153156489](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261531649.png)

- containerï¼šå®¹å™¨ï¼Œå¯ä»¥ç†è§£ä¸ºç¥ç»ç½‘ç»œçš„éª¨æ¶ï¼ˆå®šä¹‰ä¸€äº›ç»“æ„ï¼‰ï¼Œåªéœ€è¦å¾€ç»“æ„é‡ŒåŠ å…¥ä¸€äº›å†…å®¹å°±å¯ä»¥ç»„æˆç¥ç»ç½‘ç»œï¼ˆæœ¬èŠ‚è¯¾å°†å­¦ä¹ éª¨æ¶æ­å»ºï¼‰

  - æœ€å¸¸ç”¨çš„æ˜¯Moduleï¼Œä¸ºæ‰€æœ‰ç¥ç»ç½‘ç»œæä¾›åŸºç±»ï¼ˆéª¨æ¶/æ¨¡æ¿ï¼Œå¯¹æ¨¡æ¿ä¸æ»¡æ„çš„å†…å®¹è¿›è¡Œä¿®æ”¹ï¼Œå¦‚ä¸‹ä¸‹å›¾çš„`__init__` & `forward`ï¼‰ï¼Œä½ çš„æ¨¡å‹å¿…é¡»ç»§æ‰¿åœ¨Moduleç±»ä¸‹é¢ï¼ˆModuleæ˜¯çˆ¶ç±»ï¼‰

    ![image-20251026153552562](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261535655.png)

    ![image-20251026153629787](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261536879.png)

    - åˆå§‹åŒ–è¿‡ç¨‹è¦å…ˆè°ƒç”¨çˆ¶ç±»çš„åˆå§‹åŒ–å‡½æ•°`super(Model, self).__init__()`

      - selfï¼šæŒ‡Modelè¿™ä¸ªç±»

    - ç¥ç»ç½‘ç»œæ¡†æ¶å’Œè®¡ç®—æµç¨‹

      - å‰å‘ä¼ æ’­ï¼šinputç»è¿‡forwardè®¡ç®—è¿›è¡Œè¾“å‡ºoutput

        ![image-20251026154010362](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261542793.png)

        - xå…ˆç»è¿‡å·ç§¯conv1ï¼Œåœ¨ç»è¿‡éçº¿æ€§å±‚reluã€max(0, x)ã€‘,å†ç»è¿‡ä¸€æ¬¡å·ç§¯conv2ï¼Œæœ€åç»å†ç†ä¸€æ¬¡éçº¿æ€§å±‚reluã€max(0, x)ã€‘

          ![image-20251026154318785](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261543863.png)

    - forwardæºç 

      - æ¯æ¬¡è°ƒç”¨ä¼šå®šä¹‰è®¡ç®—å›¾ï¼Œåº”è¯¥åœ¨æ¯ä¸ªå­ç±»ä¸­è¿›è¡Œé‡å†™

        ![image-20251026154436480](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261544550.png)

  - containerä»¥å¤–çš„ä¸œè¥¿éƒ½æ˜¯å¾€ç»“æ„é‡Œå¡«å……çš„ä¸œè¥¿

- Convolution Layers: å·ç§¯å±‚

- Pooling Layer:æ± åŒ–å±‚

- Non-linear Activations:éçº¿æ€§æ¿€æ´»

åœ¨pycahrmé¡¹ç›®ä¸­æ–°å»ºpythonæ–‡ä»¶nn_module

```python
from torch import nn

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()# ä¼šè‡ªåŠ¨è¡¥å…¨
 
```

```python
from torch import nn
import torch

class Tudui(nn.Module):
    # å¦ä¸€ç§æ–¹æ³•ï¼šåˆ©ç”¨pycharmçš„é€‰é¡¹å¡ï¼šç‚¹å‡»codeèœå•æ ä¸‹çš„Generateï¼Œåœ¨å¼¹å‡ºçš„é¡µé¢ä¸­é€‰æ‹©Override Methodsï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ª__init__,ä»£ç è‡ªåŠ¨è¡¥å…¨
    def __init__(self):
    	super().__init__()
    
    def forward(self, input):
        output = input + 1
        return output
    
tudui = Tudui()
x = torch.tensor(1.0)
output = tudui(x)
print(output)
# tensor(2.)
    
```

è°ƒç”¨å®ä¾‹å¯¹è±¡åŠ ï¼ˆï¼‰ä¹‹æ‰€ä»¥ä¼šè°ƒç”¨forwardï¼ˆï¼‰æ–¹æ³•æ˜¯å› ä¸ºï¼šé¦–å…ˆè°ƒç”¨çˆ¶ç±»çš„`__call__`æ–¹æ³•ï¼Œçˆ¶ç±»ä¸­è¯¥æ–¹æ³•è°ƒç”¨äº†forwardï¼ˆï¼‰æ–¹æ³•ï¼Œè€Œå­ç±»é‡å†™äº†è¯¥æ–¹æ³•ï¼Œæ‰€ä»¥æœ€ç»ˆè°ƒç”¨åˆ°äº†å­ç±»çš„forwardæ–¹æ³•

![image-20251026161140649](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261611701.png)

![image-20251026161244660](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261612755.png)

![image-20251026161325694](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261613779.png)

## 16.2-super()æ–¹æ³•

### æ¦‚è¿°

super() æ˜¯python ä¸­è°ƒç”¨çˆ¶ç±»ï¼ˆè¶…ç±»ï¼‰çš„ä¸€ç§æ–¹æ³•ï¼Œåœ¨å­ç±»ä¸­å¯ä»¥é€šè¿‡super()æ–¹æ³•æ¥è°ƒç”¨çˆ¶ç±»çš„æ–¹æ³•ã€‚ã€è¶…ç±»ï¼š æ˜¯æŒ‡ 2å±‚ä»¥ä¸Šçš„ç»§æ‰¿å…³ç³»ï¼Œå‡å¦‚ Cç±»ç»§æ‰¿Bç±»ï¼ŒBç±»ç”±ç»§æ‰¿Aç±»ï¼Œé‚£ä¹ˆAç±»å°±æ˜¯Cç±»çš„è¶…ç±»ã€‘

**ä½œç”¨ï¼š**

- åœ¨ç»§æ‰¿ä¸­ï¼Œè®©ä»£ç ç»´æŠ¤æ›´åŠ ç®€å•
- è§£å†³å¤šç»§æ‰¿å¸¦æ¥çš„é‡å¤è°ƒç”¨ï¼ˆè±å½¢ç»§æ‰¿ï¼‰ã€æŸ¥æ‰¾é¡ºåºï¼ˆMROï¼‰é—®é¢˜

**è¯­æ³•ï¼š**

```python
super(type[, object-or-type])
```

> å‚æ•°ï¼š
> type â€“ ç±»ã€‚
> object-or-type â€“ ç±»ï¼Œä¸€èˆ¬æ˜¯ self

Python 3 å’Œ Python 2 çš„å¦ä¸€ä¸ªåŒºåˆ«æ˜¯: **Python 3 å¯ä»¥ä½¿ç”¨ç›´æ¥ä½¿ç”¨ super().xxx ä»£æ›¿ super(Class, self).xxx :**

### 16.2.1-superçš„ä½¿ç”¨

**1.é€šè¿‡super() æ¥è°ƒç”¨çˆ¶ç±»çš„__init__ æ„é€ æ–¹æ³•ï¼š**

```python
class Person():
      def __init__(self):
    ã€€ã€€ã€€ã€€print('æˆ‘æ˜¯Pesonçš„__init__æ„é€ æ–¹æ³•')

class Student(Person):
        def __init__ï¼ˆselfï¼‰:
    ã€€ã€€ã€€ã€€ã€€super().__init__()
   ã€€ã€€ã€€ã€€ã€€  printï¼ˆ'æˆ‘æ˜¯Studentçš„__init__æ„é€ æ–¹æ³•')

stu = Student()
-----------------------------------------
æˆ‘æ˜¯Pesonçš„__init__æ„é€ æ–¹æ³•
æˆ‘æ˜¯Studentçš„__init__æ„é€ æ–¹æ³•
```

**2 é€šè¿‡supper() æ¥è°ƒç”¨ä¸å­ç±»åŒåçš„çˆ¶ç±»æ–¹æ³•**
**2.1 å•ç»§æ‰¿**
åœ¨å•ç»§æ‰¿ä¸­ super å°±åƒå¤§å®¶æ‰€æƒ³çš„é‚£æ ·ï¼Œä¸»è¦æ˜¯ç”¨æ¥è°ƒç”¨çˆ¶ç±»çš„æ–¹æ³•çš„ã€‚

```python
class A:
    def __init__(self):
        self.n = 2

    def add(self, m):
        print('self is {0} @A.add'.format(self))
        self.n += m

class B(A):
    def __init__(self):
        self.n = 3

    def add(self, m):
        print('self is {0} @B.add'.format(self))
        super().add(m)
        self.n += 3
b = B()
b.add(2)
print(b.n)
```

æˆ‘ä»¬æ‰§è¡Œä»¥ä¸Šä»£ç ï¼Œå¾—åˆ°çš„è¾“å‡ºå¦‚ä¸‹ï¼š

```python
self is <__main__.B object at 0x106c49b38> @B.add
self is <__main__.B object at 0x106c49b38> @A.add
8
```

è¿™ä¸ªç»“æœè¯´æ˜äº†ä¸¤ä¸ªé—®é¢˜:

> 1ã€super().add(m) ç¡®å®è°ƒç”¨äº†çˆ¶ç±» A çš„ add æ–¹æ³•ã€‚
> 2ã€super().add(m) è°ƒç”¨çˆ¶ç±»æ–¹æ³• def add(self, m) æ—¶, **æ­¤æ—¶çˆ¶ç±»ä¸­ self å¹¶ä¸æ˜¯çˆ¶ç±»çš„å®ä¾‹è€Œæ˜¯å­ç±»çš„å®ä¾‹**, æ‰€ä»¥ b.add(2) ä¹‹åçš„ç»“æœæ˜¯ 5 è€Œä¸æ˜¯ 4 ã€‚

### 16.2.2-MROï¼šæ–¹æ³•æœç´¢é¡ºåº

- MROæ˜¯method resolution order,ä¸»è¦ç”¨äºåœ¨å¯¹ç»§æ‰¿æ˜¯åˆ¤æ–­æ–¹æ³•ã€å±æ€§çš„è°ƒç”¨è·¯å¾„ã€é¡ºåºã€‘ï¼Œå…¶å®ä¹Ÿå°±æ˜¯ç»§æ‰¿çˆ¶ç±»æ–¹æ³•æ—¶çš„é¡ºåºè¡¨ã€‚
- Pythonä¸­é’ˆå¯¹ç±»æä¾›äº†ä¸€ä¸ªå†…ç½®å±æ€§__mro__å¯ä»¥æŸ¥çœ‹æ–¹æ³•çš„æœç´¢é¡ºåº

```python
class C(A,B):
	pass
print(C.__mro__)
out:
(<class '__main__.C'>,<class'__main__.A'>,<class'__main__B'>,<class 'object'>)
```

åœ¨æœç´¢æ–¹æ³•æ—¶ï¼Œæ˜¯æŒ‰ç…§__mro__çš„è¾“å‡ºç»“æœä»å·¦åˆ°å³çš„é¡ºåºæŸ¥æ‰¾çš„

- å¦‚æœå½“å‰ç±»ä¸­æ‰¾åˆ°æ–¹æ³•ï¼Œå°±ç›´æ¥æ‰§è¡Œï¼Œä¸å†æœç´¢
- å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°±æŸ¥æ‰¾ä¸‹ä¸€ä¸ªç±»ä¸­æ˜¯å¦æœ‰å¯¹åº”çš„æ–¹æ³•ï¼Œå¦‚æœæ‰¾åˆ°ï¼Œå°±ç›´æ¥æ‰§è¡Œï¼Œä¸å†æœç´¢
- å¦‚æœæ‰¾åˆ°æœ€åä¸€ä¸ªç±»ï¼Œè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°æ–¹æ³•ï¼Œç¨‹åºæŠ¥é”™

**2.2 å¤šç»§æ‰¿**
åœ¨å¤šç»§æ‰¿ä¸­ï¼Œä¼šæ¶‰åŠåˆ°ä¸€ä¸ªMRO(ç»§æ‰¿çˆ¶ç±»æ–¹æ³•æ—¶çš„é¡ºåºè¡¨) çš„è°ƒç”¨æ’åºé—®é¢˜ã€‚å³ä¸¥æ ¼æŒ‰ç…§MRO é¡ºåºæ‰§è¡Œsuperæ–¹æ³•

```python
class A:
    def __init__(self):
        self.n = 2

    def add(self, m):
        print('self is {0} @A.add'.format(self))
        self.n += m

class B(A):
    def __init__(self):
        self.n = 3

    def add(self, m):
        print('self is {0} @B.add'.format(self))
        super().add(m)
        self.n += 3

class C(A):
    def __init__(self):
        self.n = 4

    def add(self, m):
        print('self is {0} @C.add'.format(self))
        super().add(m)
        self.n += 4

class D(B, C):
    def __init__(self):
        self.n = 5

    def add(self, m):
        print('self is {0} @D.add'.format(self))
        super().add(m)
        self.n += 5

d = D()
d.add(2)
print(d.n)
out:
self is <__main__.D object at 0x10ce10e48> @D.add
self is <__main__.D object at 0x10ce10e48> @B.add
self is <__main__.D object at 0x10ce10e48> @C.add
self is <__main__.D object at 0x10ce10e48> @A.add
19
```

- åŒæ ·ï¼Œä¸ç®¡å¾€ä¸Šè°ƒç”¨å‡ æ¬¡ï¼Œè°ƒç”¨çˆ¶ç±»æ–¹æ³•ä¸­ self å¹¶ä¸æ˜¯çˆ¶ç±»çš„å®ä¾‹è€Œæ˜¯å­ç±»çš„å®ä¾‹ï¼Œåœ¨ä¸Šä¾‹ä¸­éƒ½æ˜¯Dçš„å®ä¾‹åŒ–å¯¹è±¡
- D.mro() == [D,B, C, A, object] ï¼Œå¤šç»§æ‰¿çš„æ‰§è¡Œé¡ºåºä¼šä¸¥æ ¼æŒ‰ç…§mroçš„é¡ºåºæ‰§è¡Œã€‚
- æ•´ä½“çš„è°ƒç”¨æµç¨‹å›¾å¦‚ä¸‹ï¼š

```python
d = D()
d.n == 5
d.add(2)

class D(B, C):          class B(A):            class C(A):             class A:
    def add(self, m):       def add(self, m):      def add(self, m):       def add(self, m):
        super().add(m)  1.--->  super().add(m) 2.--->  super().add(m)  3.--->  self.n += m
        self.n += 5   <------6. self.n += 3    <----5. self.n += 4     <----4. <--|
        (14+5=19)               (11+3=14)              (7+4=11)                (5+2=7)
```

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261634657.png)
**å…¶å®ƒï¼š**
1.`super().__init__`ç›¸å¯¹äºç±»å.**init**ï¼Œåœ¨å•ç»§æ‰¿ä¸Šç”¨æ³•åŸºæœ¬æ— å·®åˆ«
2.ä½†åœ¨å¤šç»§æ‰¿ä¸Šæœ‰åŒºåˆ«ï¼Œsuperæ–¹æ³•èƒ½ä¿è¯æ¯ä¸ªçˆ¶ç±»çš„æ–¹æ³•åªä¼šæ‰§è¡Œä¸€æ¬¡ï¼Œè€Œä½¿ç”¨ç±»åçš„æ–¹æ³•ä¼šå¯¼è‡´æ–¹æ³•è¢«æ‰§è¡Œå¤šæ¬¡ã€‚
3.å¤šç»§æ‰¿æ—¶ï¼Œä½¿ç”¨superæ–¹æ³•ï¼Œå¯¹çˆ¶ç±»çš„ä¼ å‚æ•°ï¼Œåº”è¯¥æ˜¯ç”±äºpythonä¸­superçš„ç®—æ³•å¯¼è‡´çš„åŸå› ï¼Œå¿…é¡»æŠŠå‚æ•°å…¨éƒ¨ä¼ é€’ï¼Œå¦åˆ™ä¼šæŠ¥é”™
4.å•ç»§æ‰¿æ—¶ï¼Œä½¿ç”¨superæ–¹æ³•ï¼Œåˆ™ä¸èƒ½å…¨éƒ¨ä¼ é€’ï¼Œåªèƒ½ä¼ çˆ¶ç±»æ–¹æ³•æ‰€éœ€çš„å‚æ•°ï¼Œå¦åˆ™ä¼šæŠ¥é”™

# 17-å·ç§¯æ“ä½œ

> å·ç§¯ç›¸å½“äºä¸€ä¸ªé¥¼, ç›–åœ¨ä¸Šé¢,åšè¿ç®—

![image-20251026171554706](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261715853.png)

- 1d: 1ç»´å·ç§¯ç¥ç»ç½‘ç»œ
- 2d: 2ç»´å·ç§¯ç¥ç»ç½‘ç»œï¼ˆæ¯”å¦‚å›¾åƒï¼‰ï¼Œä¸»è¦å¯¹2dè¿›è¡Œè®²è§£



**torch.nn** VS **torch.nn.functional**

- troch.nnæ˜¯å¯¹ torch.functionalçš„å°è£…ï¼Œæ›´åŠ åˆ©äºæˆ‘ä»¬ä½¿ç”¨
- torch.nn.functionalä½¿ç”¨èµ·æ¥æ›´éº»çƒ¦,é‡Œé¢çš„å‡½æ•°è·Ÿtorch.nnæ˜¯å¯¹åº”çš„å…³ç³»

![image-20251026172147569](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261721703.png)

æ¥çœ‹torch.nn.functionalä¸‹çš„conv2d

![image-20251026172233327](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261722470.png)

- inputï¼šè¾“å…¥ï¼Œæ ¼å¼ä¸ºï¼ˆminibatchï¼Œ é€šé“æ•°ï¼Œé•¿ï¼Œå®½ï¼‰
- weightï¼šæƒé‡ï¼Œå¯ä»¥çœ‹æˆå·ç§¯æ ¸ï¼Œæ ¼å¼ä¸ºï¼ˆ è¾“å‡ºé€šé“æ•°ï¼Œå…¶ä»–è®¡ç®—ã€groupsä¸€èˆ¬å–ä¸º1ï¼Œ groupæ˜¯åˆ†ç»„å·ç§¯ï¼Œå¯¹ä¸åŒçš„é€šé“ä½¿ç”¨ä¸åŒçš„å·ç§¯æ ¸ã€‘ï¼Œé•¿ï¼Œå®½ï¼‰
- biasï¼šåç½®
- strideï¼šæ­¥è¿›
- padding:åœ¨å›¾åƒçš„å·¦å³ä¸¤è¾¹è¿›è¡Œå¡«å……ï¼Œå–å€¼å¯ä»¥ä¸ºä¸€ä¸ªæ•°æˆ–è€…å…ƒç»„ã€é•¿ï¼Œå®½ã€‘ï¼Œé»˜è®¤å€¼ä¸º0ï¼ˆä¸è¿›è¡Œå¡«å……ï¼‰



![image-20251026172551510](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261725613.png)

- å·¦è¾¹æ˜¯5*5å¤§å°çš„å›¾åƒï¼Œæ¯ä¸ªæ•°å­—ä»£è¡¨åœ¨è¯¥ä¸ªåƒç´ ä¸­é¢œè‰²æ˜¾ç¤º

- å·ç§¯æ ¸ï¼š3*3å¤§å°çš„

- å·ç§¯è¿‡ç¨‹ï¼šå…ˆå°†å·ç§¯æ ¸ä¸å›¾åƒå·¦ä¸Šè§’è¿›è¡ŒåŒ¹é…ï¼Œå¯¹åº”ä½ç½®ç›¸ä¹˜å†æœ€åæ±‚å’Œï¼Œè¯¥ä½ç½®çš„ç»“æœæ˜¯$1*1+2*2+0*1+0*0+1*1+2*0+1*2+2*1+1*0=10$ï¼Œå°†å…¶è¿›è¡Œè¾“å‡º

  ![image-20251026172725204](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261727280.png)

  - æ¥ä¸‹é‡Œéœ€è¦å°†å·ç§¯æ ¸å‘å³æ•´ä½“ç§»åŠ¨ä¸€æ ¼ï¼ˆsride=1ï¼‰,è¯¥ä½ç½®çš„ç»“æœæ˜¯$2*1+0*2+3*1+1*0+2*1+3*0+2*2+1*1+1*0=12$,å°†12è¿›è¡Œè¾“å‡º

    ![image-20251026172950138](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261729222.png)

  - æ¥ä¸‹é‡Œéœ€è¦å°†å·ç§¯æ ¸å‘å³æ•´ä½“ç§»åŠ¨ä¸€æ ¼ï¼ˆsride=1ï¼‰,è¯¥ä½ç½®çš„ç»“æœæ˜¯$0*1+3*2+1*1+2*0+3*1+1*0+1*2+0*1+0*0=12$,å°†12è¿›è¡Œè¾“å‡º

    ![image-20251026173121336](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261731433.png)

  æ­¤æ—¶ä¸å›¾åƒå³è¾¹ç¼˜é‡åˆï¼Œå³è¾¹æ— æ³•ç§»åŠ¨ï¼Œæ­¤æ—¶éœ€è¦å‘ä¸‹æ¢ä¸€è¡Œä»å·¦è¾¹è¿˜æ˜¯è¿›è¡ŒåŒ¹é…

  > ![image-20251026173510342](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261735413.png)
  >
  > - sHï¼šæ§åˆ¶æ¨ªå‘çš„æ­¥è¿›ï¼ˆé»˜è®¤ä¸º1ï¼‰
  > - sWï¼šæ§åˆ¶çºµå‘çš„æ­¥è¿›ï¼ˆé»˜è®¤ä¸º1ï¼‰

  - è¯¥ä½ç½®çš„ç»“æœæ˜¯$0*1+1*2+2*1+1*0+2*1+1*0+5*2+2*1+3*0=18$

    ![image-20251026173646307](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261736395.png)

  - ç»§ç»­å‘å³æ»‘åŠ¨ä¸€å—ï¼Œè¯¥ä½ç½®çš„ç»“æœ$1*1+2*2+3*1+2*0+1*1+0*0+2*2+3*1+1*0=16$

    ![image-20251026173848879](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261738989.png)

  - ç»§ç»­å‘å³æ»‘åŠ¨ä¸€å—ï¼Œè¯¥ä½ç½®çš„ç»“æœ$2*1+3*2+1*1+1*0+0*1+0*0+3*2+1*1+1*0=16$

    ![image-20251026173919833](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261739924.png)

  - æ­¤æ—¶ä¸å›¾åƒå³è¾¹ç¼˜é‡åˆï¼Œå³è¾¹æ— æ³•ç§»åŠ¨ï¼Œæ­¤æ—¶éœ€è¦å‘ä¸‹æ¢ä¸€è¡Œä»å·¦è¾¹è¿˜æ˜¯è¿›è¡ŒåŒ¹é…

  - è¯¥ä½ç½®çš„ç»“æœ$1*1+2*2+1*1+5*0+2*1+3*0+2*2+1*1+1*0=13$

    ![image-20251026174014134](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261740227.png)

  - ç»§ç»­å‘å³æ»‘åŠ¨ä¸€å—ï¼Œè¯¥ä½ç½®çš„ç»“æœ$2*1+1*2+0*1+2*0+3*1+1*0+1*2+0*1+1*0=9$

    ![image-20251026174130530](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261741641.png)

  - ç»§ç»­å‘å³æ»‘åŠ¨ä¸€å—ï¼Œè¯¥ä½ç½®çš„ç»“æœ$1*1+0*2+0*1+3*0+1*1+1*0+0*2+1*1+1*0=3$

    ![image-20251026174235360](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261742475.png)

  - å·ç§¯åçš„è¾“å‡ºç»“æœï¼ˆstride=1ï¼‰

    ![image-20251026180222915](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261802020.png)

    > å½“stride=2æ—¶ï¼Œè¾“å‡ºä¸º2*2çš„çŸ©é˜µ

```python
# éªŒè¯ä¸Šé¢çš„æ¨å¯¼æ˜¯å¦å‡†ç¡®
import torch
import torch.nn.functional as F

input = torch.tensor([[1, 2, 0, 3, 1],
                     [0, 1, 2, 3, 1],
                     [1, 2, 1, 0, 0],
                     [5, 2, 3, 1, 1],
                     [2, 1,0, 1, 1]])# ä¸¤ä¸ªä¸­æ‹¬å·è¡¨ç¤º2ä¸ºçŸ©é˜µ
# å·ç§¯æ ¸
kernel = torch.tensor([[1, 2, 1],
                     [0, 1, 1],
                     [2, 1, 0]])
print(input.shape)
# torch.Size([5, 5])
# sizeå€¼ä¸æ»¡è¶³è¯´æ˜æ–‡æ¡£ä¸­è¾“å…¥æ ¼å¼ï¼šï¼ˆminibatchï¼Œin_channels,iH, iWï¼‰
print(kernel.shape)
# torch.Size([3, 3])
# sizeå€¼ä¸æ»¡è¶³è¯´æ˜æ–‡æ¡£ä¸­è¾“å‡ºæ ¼å¼ï¼šï¼ˆout_channelsï¼Œin_channels/groups,kH, kWï¼‰
# éœ€è¦å¯¹å…¶è¿›è¡Œè½¬æ¢
input = torch.reshape(input, (1, 1, 5, 5))
"""
ç¬¬ä¸€ä¸ª1ï¼šbatchsize=1
ç¬¬äºŒä¸ª1ï¼šé€šé“ä¸º1
ï¼ˆ5ï¼Œ5ï¼‰ ï¼šï¼ˆé•¿ï¼Œå®½ï¼‰
"""
kernel = torch.reshape(kernel, (1, 1, 3, 3))
print(input.shape)
# torch.Size([1, 1, 5, 5])
print(kernel.shape)
# torch.Size([1, 1, 3, 3])

output = F.conv2d(input, kernel, stride=1)
print(output)
# ä¸å‰é¢æ¨å¯¼ç»“æœä¸€è‡´ï¼Œæ¯ä¸€è¡Œ&æ¯ä¸€åˆ—ç›¸å½“äºç§»åŠ¨2æ¬¡ï¼ŒåŠ ä¸Šåˆå§‹ä½ç½®ï¼Œæ‰€ä»¥å½¢çŠ¶ä¸ºtorch.Size([1, 1, 3, 3])
```

![image-20251101201746279](https://typora-alex2.oss-cn-shanghai.aliyuncs.com/202511012017690.png)

â€‹	

```python
output2 = F.conv2d(input, kernel, stride=2)
print(output2)
# æ¯ä¸€è¡Œ&æ¯ä¸€åˆ—ç›¸å½“äºç§»åŠ¨3æ¬¡ï¼ŒåŠ ä¸Šåˆå§‹ä½ç½®ï¼Œæ‰€ä»¥å½¢çŠ¶ä¸ºtorch.Size([1, 1, 2, 2])
```

![image-20251026180404541](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261804637.png)

**padding=1**

ç›¸å½“äºåŸå›¾åƒä¸Šä¸‹å·¦å³è¾¹ç¼˜å‡å¢åŠ ä¸€è¡Œ/ä¸€åˆ—ï¼Œå¡«å……å€¼é»˜è®¤ä¸º0ï¼›

![image-20251026180759719](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261807839.png)

å·ç§¯è¿‡ç¨‹å·ç§¯æ ¸ä»å¡«å……åçš„å·¦ä¸Šè§’è¿›è¡ŒåŒ¹é…

![image-20251026180812276](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261808408.png)

```python
output3 = F.conv2d(input, kernel, stride=1, padding=1)
print(output3)

```

![image-20251101201841199](https://typora-alex2.oss-cn-shanghai.aliyuncs.com/202511012018629.png)

æ˜æ˜¾è¾“å‡ºå°ºå¯¸å˜å¤§äº†ï¼ŒéªŒè¯ä¸‹ï¼Œç¬¬ä¸€ä¸ªæ ¼å­çš„è®¡ç®—ç»“æœåªæœ‰ä¸­é—´çš„$1*1=1$

![image-20251026181031977](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261810100.png)

# 18-å·ç§¯å±‚

![image-20251026195623374](https://typora3.oss-cn-shanghai.aliyuncs.com/202510261956594.png)

- in_channels:è¾“å…¥é€šé“æ•°ï¼ˆéœ€è¦è®¾ç½®ï¼Œå¸¸ç”¨ï¼‰
- out_channels:è¾“å‡ºé€šé“æ•°ï¼ˆéœ€è¦è®¾ç½®ï¼Œå¸¸ç”¨ï¼‰
- kernel_size:å·ç§¯æ ¸å¤§å°ï¼Œå–å€¼å¯ä»¥ä¸ºintæˆ–è€…tupleç±»å‹ã€ä¸è§„åˆ™å½¢çŠ¶ï¼Œæ¯”å¦‚ï¼ˆ1ï¼Œ 2ï¼‰ã€‘ï¼ˆéœ€è¦è®¾ç½®ï¼Œå¸¸ç”¨ï¼‰
- stride:å·ç§¯è¿‡ç¨‹çš„æ­¥è¿›ï¼ˆæœ‰é»˜è®¤å–å€¼ä¸º1ï¼Œå¸¸ç”¨ï¼‰
- paddingï¼šå¯¹åŸå›¾åƒå¤–å›´è¦è¡¥å……å‡ å±‚ï¼ˆæœ‰é»˜è®¤å–å€¼0ï¼Œå¸¸ç”¨ï¼‰
- dilationï¼šå·ç§¯æ ¸ä¸­å…ƒç´ çš„è·ç¦»ï¼Œä¸å¸¸ç”¨ï¼ˆæœ‰é»˜è®¤å–å€¼ï¼‰
  - å…·ä½“å¯ä»¥çœ‹https://github.com/vdumoulin/conv_arithmetic/blob/master/README.mdçš„gifåŠ¨ç”»å±•ç¤º
- groups:ä¸€èˆ¬ä¸º1ï¼Œå¦‚æœä¸ä¸º1åˆ™ä»£è¡¨åˆ†ç»„å·ç§¯ï¼ˆå‡ ä¹é‡ä¸åˆ°ï¼‰ï¼ˆæœ‰é»˜è®¤å‚æ•°ï¼‰
- biasï¼šæ˜¯å¦éœ€è¦åç½®ï¼ˆæœ‰é»˜è®¤å‚æ•°ï¼‰
- padding_mode:paddingåŒºåŸŸå¡«å……æ¨¡å¼ï¼ˆæœ‰é»˜è®¤å‚æ•°ï¼‰

![image-20251026200202008](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262002167.png)

è§£æin_channels & out_channels

å¦‚æœin_channels=1 ä¸”åªæœ‰1ä¸ªå·ç§¯æ ¸ï¼Œé‚£ä¹ˆout_channel=1

![image-20251026201123872](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262011038.png)

å¦‚æœin_channels=1 ä¸”æœ‰2ä¸ªå·ç§¯æ ¸ï¼Œé‚£ä¹ˆout_channel=2ã€‚è®¸å¤šç®—æ³•éƒ½æ˜¯ä¸ç®—å¢åŠ å·ç§¯æ•°æ¥æå‡ç®—æ³•æ•ˆæœ

![image-20251026201436576](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262014746.png)

> å·ç§¯ç»“æœä¸æ˜¯å·ç§¯çš„ç»“æœ

åœ¨pycahrmé¡¹ç›®ä¸­æ–°å»ºpythonæ–‡ä»¶nn_conv2d

```python
import torch
import torchvision
from torch.utils.data import DataLoader
from torch import nn
from torch.nn import Conv2d
from torch.utils.tensorboard import SummaryWriter

dataset = torchvision.datasets.CIFAR10("./dataset/CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)

dataloader = DataLoader(dataset, batch_size=64)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.conv1 = Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)
        # first 3:è¾“å…¥ä¸ºå½©è‰²å›¾åƒï¼ˆ3é€šé“ï¼‰
        # 6ï¼šout_channel size
        # second 3ï¼š kernel size
    def forward(self, x):
        x = self.conv1(x)
        return x
tudui = Tudui()
print(tudui)
# æŸ¥çœ‹ç½‘ç»œç»“æ„
"""
Tudui(
(conv1):ConV2d(3, 6, kernel(3, 3), stride(1, 1))
)
"""   
# ä¼šå°†kernel_size=3 æ‹†è§£ä¸ºï¼ˆ3ï¼Œ 3ï¼‰
# ä¼šå°†stride=1 æ‹†è§£ä¸ºï¼ˆ1ï¼Œ 1ï¼‰

# ç”¨tensorboardè¿›è¡Œå¯è§†åŒ– 
writer = SummaryWriter("../logs")
step = 0
for data in dataloader:
    imgs, targets = data
    output = tudui(imgs)
    print(imgs.shape)
    # tensor.Size([64, 3, 32, 32])
    # å¯¹åº”å·ç§¯ç¥ç»ç½‘ç»œçš„è¾“å…¥æ•°æ®æ ¼å¼ï¼šï¼ˆminibatchï¼Œin_channels,iH, iWï¼‰
    print(output.shape)
    # tensor.Size([64, 6, 30, 30]), è¿™é‡Œè®¾ç½®çš„batch_size=64
    # ç”±äºå·ç§¯æ ¸æ˜¯ï¼ˆ3ï¼Œ 3ï¼‰, æ‰€ä»¥å·ç§¯åçš„å°ºå¯¸å˜ä¸ºï¼ˆ30ï¼Œ30 ï¼‰
    writer.add_images("input", imgs, step)
    writer.add_images("output", output, step)
    step = step + 1 
    
    # ä¼šæŠ¥é”™ï¼šå› ä¸ºè¾“å‡ºå›¾åƒæ˜¯6ä¸ªchannelï¼Œ ä½†æ˜¯å½©è‰²å›¾åƒåªèƒ½æ˜¾ç¤º3ä¸ªchannel,éœ€è¦å¯¹ä»£ç è¿›è¡Œä¿®æ”¹
```

```python
import torch
import torchvision
from torch.utils.data import DataLoader
from torch import nn
from torch.nn import Conv2d
from torch.utils.tensorboard import SummaryWriter

dataset = torchvision.datasets.CIFAR10("./dataset/CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)

dataloader = DataLoader(dataset, batch_size=64)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.conv1 = Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)
        # first 3:è¾“å…¥ä¸ºå½©è‰²å›¾åƒï¼ˆ3é€šé“ï¼‰
        # 6ï¼šout_channel size
        # second 3ï¼š kernel size
    def forward(self, x):
        x = self.conv1(x)
        return x
tudui = Tudui()
print(tudui)
# æŸ¥çœ‹ç½‘ç»œç»“æ„
"""
Tudui(
(conv1):ConV2d(3, 6, kernel(3, 3), stride(1, 1))
)
"""   
# ä¼šå°†kernle=1 æ‹†è§£ä¸ºï¼ˆ3ï¼Œ 3ï¼‰
# ä¼šå°†stride=1 æ‹†è§£ä¸ºï¼ˆ1ï¼Œ 1ï¼‰

# ç”¨tensorboardè¿›è¡Œå¯è§†åŒ– 
writer = SummaryWriter("../logs")
step = 0
for data in dataloader:
    imgs, targets = data
    output = tudui(imgs)
    print(imgs.shape)
    # tensor.Size([64, 3, 32, 32])
    # å¯¹åº”å·ç§¯ç¥ç»ç½‘ç»œçš„è¾“å…¥æ•°æ®æ ¼å¼ï¼šï¼ˆminibatchï¼Œin_channels,iH, iWï¼‰
    print(output.shape)
    # tensor.Size([64, 6, 30, 30]), è¿™é‡Œè®¾ç½®çš„batch_size=64
    # ç›®çš„æ˜¯æå–è¾“å…¥çš„æ›´å¤šç‰¹å¾ã€‚åˆšå¼€å§‹è¾“å…¥æ˜¯RGBä¸‰ä¸ªchannelsï¼Œç»è¿‡6ä¸ªå·ç§¯æ ¸ä¹‹åå°±æå–å‡ºäº†6ä¸ªç‰¹å¾å³channelsã€‚
    # ç”±äºå·ç§¯æ ¸æ˜¯ï¼ˆ3ï¼Œ 3ï¼‰, æ‰€ä»¥å·ç§¯åçš„å°ºå¯¸å˜ä¸ºï¼ˆ30ï¼Œ30 ï¼‰
    # è¦ä¿è¯å°ºå¯¸ä¸å˜ï¼Œåˆ™éœ€è¦è®¾ç½®paddingçš„å€¼ä¸º2
    writer.add_images("input", imgs, step)
    #  tensor.Size([64, 6, 30, 30]) --> [xxx, 3, 30, 30](å¢åŠ batchsize)
    output = torch.reshape(output, (-1, 3, 30, 30))
    writer.add_images("output", output, step)
    step = step + 1 
    
writer.close()
```

å¯ä»¥çœ‹åˆ°åæ ‡Projecté¡µé¢çš„logsæ–‡ä»¶å¤¹é‡Œä¼šç”Ÿæˆä¸€ä¸ªæ–°çš„logæ–‡ä»¶ï¼Œç„¶ååœ¨Terminalä¸­è¾“å…¥`tensorboard --logdir=logs`,ç‚¹å‡»æ˜¾ç¤ºçš„ç«¯å£ï¼Œå¯ä»¥åœ¨æ˜¾ç¤ºçš„é¡µé¢ä¸­çœ‹åˆ°å›¾ç‰‡

![image-20251026204739839](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262047073.png)

![image-20251026204756005](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262047376.png)

batchsizeä»64å˜ä¸º128



è¾“å‡ºå°ºå¯¸è®¡ç®—å…¬å¼

![image-20251026205225766](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262052901.png)

# 19-æ± åŒ–å±‚ï¼šæœ€å¤§æ± åŒ–çš„ä½¿ç”¨

![image-20251026205438908](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262054116.png)

- MaxPoolï¼š æœ€å¤§æ± åŒ–ï¼Œä¹Ÿå«ä¸‹é‡‡æ ·
- maxUnpool:ä¸MaxPoolç›¸åï¼Œæ‰€ä»¥å«ä¸Šé‡‡æ ·

![image-20251026213845440](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262138611.png)

![image-20251026213902802](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262139942.png)

- kernel_size: å–æœ€å¤§å€¼çš„çª—å£å¤§å°ï¼Œå–å€¼å¯ä»¥ä¸ºintæˆ–è€…tupleï¼ˆè·Ÿå·ç§¯å±‚ç±»ä¼¼ï¼‰

- strideï¼šæ­¥è¿›ï¼Œå–å€¼å¯ä»¥ä¸ºintæˆ–è€…tupleï¼ˆæ¨ªå‘ï¼Œçºµå‘ï¼‰ï¼Œä»–çš„é»˜è®¤å€¼è·Ÿkernel_sizeä¸€è‡´

- dilation:å¦‚ä¸‹å›¾è“è‰²é˜´å½±æ‰€ç¤ºè“è‰²é˜´å½±ç¬¬ä¸€è¡Œç¬¬ä¸€ä¸ªé˜´å½±å…ƒç´ å’Œç¬¬äºŒä¸ªé˜´å½±å…ƒç´ ä¸­é—´é—´éš”äº†ä¸€ä¸ªï¼Œä¹Ÿå«ç©ºæ´å·ç§¯ï¼ˆä¸­é—´æœ‰ç©ºéš”ï¼‰

  ![image-20251026215000532](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262150661.png)

- return_indices:ç”¨çš„æ¯”è¾ƒå°‘

- ceil_mode: å½“ä¸ºtrueæ—¶ï¼Œåˆ™ä¼šé‡‡ç”¨ceilæ¨¡å¼ï¼ˆç±»ä¼¼å‘ä¸Šå–æ•´ï¼‰è€Œéflooræ¨¡å¼ï¼ˆç±»ä¼¼å‘ä¸‹å–æ•´ï¼Œé»˜è®¤ä¸ºFalseï¼‰

  ![image-20251026215338300](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262153451.png)

æœ€å¤§æ± åŒ–ï¼šå°†kernelæ”¾åœ¨å¯¹åº”çš„å›¾åƒåƒç´ åŒºåŸŸä¸Šï¼Œè®¡ç®—$max(1*a, 2*b, 0*c, 0*d, 1*e, 2*f, 1*g, 2*h, 1*i)$ï¼Œä½œä¸ºè¯¥åŒºåŸŸçš„è¾“å‡ºå€¼ï¼Œå‡è®¾ä¸º2ï¼›

![image-20251026215616011](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262156149.png)

ç„¶åå°†æ± åŒ–kernelå‘å³ç§»åŠ¨3æ ¼ï¼ˆè¦ä¸kernel_sizeä¿æŒä¸€è‡´ï¼‰ï¼Œè€Œæ­¤æ—¶å‘ç°è¶…å‡ºå›¾åƒè¾¹ç•Œï¼Œæ­¤æ—¶å°±éœ€è¦å†³å®šæ˜¯å¦è¦å–è¿™6ä¸ªæ•°çš„æœ€å¤§å€¼$max(3*a, 1*b, 3*d, 1*e,  0*g, 0*h)$ã€å‡è®¾è¾“å‡ºå€¼ä¸º3ã€‘è¿˜æ˜¯æ”¾å¼ƒï¼Œè¿™å°†ç”±**ceil_mode**æ¥å†³å®šï¼ˆTrueï¼šä¿ç•™è¿™6ä¸ªæ•°ï¼‰

![image-20251026215906439](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262159572.png)

å‘ä¸‹ç§»åŠ¨3æ ¼ï¼Œå¹¶ä»å·¦è¾¹å¼€å§‹æ± åŒ–ï¼Œè€Œæ­¤æ—¶å‘ç°è¶…å‡ºå›¾åƒè¾¹ç•Œï¼Œæ­¤æ—¶å°±éœ€è¦å†³å®šæ˜¯å¦è¦å–è¿™6ä¸ªæ•°çš„æœ€å¤§å€¼$max(5*a, 2*b, 3*c, 5*d,  1*e, 0*f)$ã€å‡è®¾è¾“å‡ºå€¼ä¸º5ã€‘è¿˜æ˜¯æ”¾å¼ƒï¼Œè¿™å°†ç”±**ceil_mode**æ¥å†³å®šï¼ˆTrueï¼šä¿ç•™è¿™6ä¸ªæ•°ï¼‰![img](https://i-blog.csdnimg.cn/blog_migrate/90a3c6a8714ff0bee3f6289a1891caac.jpeg)

![image-20251026220226741](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262202888.png)

å‘å³ç§»åŠ¨3æ ¼ï¼Œè€Œæ­¤æ—¶å‘ç°è¶…å‡ºå›¾åƒè¾¹ç•Œï¼Œæ­¤æ—¶å°±éœ€è¦å†³å®šæ˜¯å¦è¦å–è¿™4ä¸ªæ•°çš„æœ€å¤§å€¼$max(1*a, 1*b, 1*d, 1*e)$ã€å‡è®¾è¾“å‡ºå€¼ä¸º1ã€‘è¿˜æ˜¯æ”¾å¼ƒï¼Œè¿™å°†ç”±**ceil_mode**æ¥å†³å®šï¼ˆTrueï¼šä¿ç•™è¿™4ä¸ªæ•°ï¼‰

![image-20251026220423311](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262204454.png)

æœ€ç»ˆceil_mode=True å’ŒFalseçš„åŒºåˆ« 

![image-20251026220541014](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262205220.png)

åœ¨pycahrmé¡¹ç›®ä¸‹æ–°å»ºpythonæ–‡ä»¶nn_maxpool

```python
import torch
from torch im
from torch.nn import MaxPool2d

input = torch.tensor([[1, 2, 0, 3, 1],
                     [0, 1, 2, 3, 1],
                     [1, 2, 1, 0, 0],
                     [5, 2, 3, 1, 1],
                     [2, 1,0, 1, 1]])# ä¸¤ä¸ªä¸­æ‹¬å·è¡¨ç¤º2ä¸ºçŸ©é˜µ
input = torch.reshape(input, (-1, 1, 5, 5))
# input_channel=1
print(input.shape)
# torch.Size([1, 1, 5, 5])

class Tudui(nn.Module):
    def __init__():
        super(Tudui, self).__init__()
        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=True)
        
    def forward(self, input):
        output = self.maxpool1(input)
        return output
    
tudui = Tudui()
output = tudui(input)
print(output)
# å¯èƒ½ä¼šæŠ¥é”™ï¼š "max_pool2d_with_indices_cpu" not implemented for 'Long", å¦‚æœinputä¸­çš„å…ƒç´ æ˜¯æ•´æ•°ï¼Œä¸ä¼šå¯¹å…¶è¿›è¡Œæ± åŒ–ï¼Œéœ€è¦å°†å…¶è½¬åŒ–ä¸ºæµ®ç‚¹æ•°
```

```python
# ceil_mode=True
import torch
from torch im
from torch.nn import MaxPool2d

input = torch.tensor([[1, 2, 0, 3, 1],
                     [0, 1, 2, 3, 1],
                     [1, 2, 1, 0, 0],
                     [5, 2, 3, 1, 1],
                     [2, 1,0, 1, 1]], dtype=torch.float32)# ä¸¤ä¸ªä¸­æ‹¬å·è¡¨ç¤º2ä¸ºçŸ©é˜µ
input = torch.reshape(input, (-1, 1, 5, 5))
# input_channel=1
print(input.shape)
# torch.Size([1, 1, 5, 5])

class Tudui(nn.Module):
    def __init__():
        super(Tudui, self).__init__()
        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=True)
        
    def forward(self, input):
        output = self.maxpool1(input)
        return output
    
tudui = Tudui()
output = tudui(input)
print(output)
```

![image-20251026221607699](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262216836.png)

```python
# ceil_mode=False
import torch
from torch im
from torch.nn import MaxPool2d

input = torch.tensor([[1, 2, 0, 3, 1],
                     [0, 1, 2, 3, 1],
                     [1, 2, 1, 0, 0],
                     [5, 2, 3, 1, 1],
                     [2, 1,0, 1, 1]], dtype=torch.float32)# ä¸¤ä¸ªä¸­æ‹¬å·è¡¨ç¤º2ä¸ºçŸ©é˜µ
input = torch.reshape(input, (-1, 1, 5, 5))
# input_channel=1
print(input.shape)
# torch.Size([1, 1, 5, 5])

class Tudui(nn.Module):
    def __init__():
        super(Tudui, self).__init__()
        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=False)
        
    def forward(self, input):
        output = self.maxpool1(input)
        return output
    
tudui = Tudui()
output = tudui(input)
print(output)
```

![image-20251026221649262](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262216394.png)

**æœ€å¤§æ± åŒ–çš„ä½œç”¨**

ä¿ç•™è¾“å…¥çš„ç‰¹å¾ï¼ŒåŒæ—¶å°†æ•°æ®é‡å‡å°ï¼ˆ5 * 5 ---> 2*2 / 1 * 1ï¼Œå¯ä»¥æƒ³è±¡æˆ1080pè§†é¢‘å˜ä¸º720pï¼Œä¹Ÿä¸å½±å“è§†é¢‘ä¼ è¾¾ä¿¡æ¯å†…å®¹çš„è´¨é‡ï¼Œ ä½†è§†é¢‘å¤§å°ä¼šå‡å°å¾ˆå¤šï¼‰,è®­ç»ƒæ•°æ®å°‘äº†ï¼Œå¯¹æ•´ä¸ªç½‘ç»œæ¥è¯´å‚æ•°å‡å°‘äº†ï¼Œè®­ç»ƒé€Ÿåº¦ä¹Ÿå°±å¢å¿«äº†

```python
# å¯è§†åŒ–
import torch
import torchvision
from torch im
from torch.nn import MaxPool2d
from torch.utils.data import DataLoader

dataset = torchvision.datasets.CIFAR10("./dataset/CIFAR10", train=False, download=True, transform=torchvision.transforms.ToTensor())
datalaoder = DataLoader(dataset, batch_size=64)


class Tudui(nn.Module):
    def __init__():
        super(Tudui, self).__init__()
        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=False)
        
    def forward(self, input):
        output = self.maxpool1(input)
        return output
    
tudui = Tudui()

writer = SummaryWriter("logs_maxpool")
step = 0
for data in datalaoder:
    imgs, target = data
    writer.add_images("input", imgs, step)
    output = tudui(imgs)
    # æ± åŒ–ä¸ä¼šæœ‰å¤šä¸ªchannelï¼Œè¾“å…¥å›¾åƒchannelä¸º3ï¼Œæ± åŒ–åè¾“å‡ºå›¾åƒä»ç„¶æ˜¯3ç»´çš„
    writer.add_images("output", output, step)
    step = step + 1
    
writer.close()
```

åœ¨terminal ä¸­è¾“å…¥tensorboard --logdir=logs_maxpool,ç‚¹å‡»è¾“å‡ºçš„ç«¯å£ï¼Œåœ¨å¼¹å‡ºçš„ç½‘é¡µä¸­å¯ä»¥çœ‹åˆ°è¾“å‡ºç»“æœ

![image-20251026223115027](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262231451.png)

![image-20251026223129196](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262231491.png)

å¤§éƒ¨åˆ†çš„ç½‘ç»œéƒ½ä¼šé‡‡ç”¨å·ç§¯+æ± åŒ–+éçº¿æ€§å±‚

# 20-éçº¿æ€§æ¿€æ´»

éçº¿æ€§æ¿€æ´»ä¸»è¦æ˜¯ç»™ç¥ç»ç½‘ç»œå¼•å…¥éçº¿æ€§ç‰¹æ€§(éçº¿æ€§ç‰¹å¾è¶Šå¤šï¼Œæ‰å¯ä»¥è®­ç»ƒå‡ºç¬¦åˆå„ç§ç‰¹å¾çš„æ¨¡å‹ï¼Œæé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›)ï¼Œæ²¡æœ‰æ¿€æ´»å‡½æ•°çš„ç¥ç»ç½‘ç»œå®é™…ä¸Šæ˜¯çº¿æ€§å¯åŠ çš„ï¼ˆæ¯”å¦‚å‰é¢çš„æ± åŒ–å’Œå·ç§¯ï¼Œéƒ½å¯ä»¥çœ‹æˆæ˜¯çº¿æ€§å›å½’æ¨¡å‹ï¼‰ï¼Œé‚£ä¹ˆå¤šçº¿æ€§å±‚å…¶å®å¯ä»¥å½’ä¸ºä¸€å±‚ã€‚åªå…·æœ‰çº¿æ€§çš„ç¥ç»ç½‘ç»œè¡¨è¾¾èƒ½åŠ›æå…¶æœ‰é™ã€‚å¸¸è§çš„éçº¿æ€§æ¿€æ´»æœ‰

- ReLU(x)=max(0, x)

  ![image-20251026223741097](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262237381.png)

- N:batch_size(ä¸‹ä¸‹å›¾ä¸­)
- *ï¼šå¯ä»¥æ˜¯ä»»æ„å½¢çŠ¶

![image-20251026223828135](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262238294.png)

- Sigmoid()å‡½æ•°:ä¼šæŠŠè¾“å…¥çš„æ•°å€¼å‹ç¼©åˆ°0å’Œ1ä¹‹é—´,é€‚åˆç”¨åœ¨äºŒåˆ†ç±»ä»»åŠ¡çš„è¾“å‡ºå±‚ã€‚

  ![image-20251026223943437](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262239711.png)

pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonæ–‡ä»¶nn_relu

```python
import torch
from torch import nn
from torch.nn import ReLU

input = torch.tensor([[1, -0.5],
                     [-1, 3]])

# éœ€è¦æŒ‡å®šbatch_size
input = torch.reshape(input, (-1, 1, 2, 2))
print(input.shape)
# torch.Size([1, 1, 2, 2])

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.relu1 = ReLU()
        
    def forward(self, input):
        output = self.relu1(input)
        return output
    
tudui = Tudui()
output = tudui(input)
print(output)
```

è§£é‡ŠReLUçš„å‚æ•°inplace: æ˜¯å¦å°±åœ°ä¿®æ”¹ï¼ˆå¸¸ç”¨å’Œé»˜è®¤å€¼éƒ½æ˜¯Falseï¼Œé˜²æ­¢åŸå§‹æ•°æ®è¢«ä¿®æ”¹å’Œä¸¢å¤±ï¼‰

![image-20251026224652084](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262246258.png)

ä¸Šè¿°ä»£ç ç»“æœï¼šè´Ÿæ•°éƒ½è¢«æˆªæ–­äº†ï¼Œç”¨0ä»£æ›¿ï¼Œæ•´æ•°ä»ç„¶è¢«ä¿ç•™

![image-20251026225015163](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262250308.png)

> ReLUå‡½æ•°å¯¹å›¾åƒçš„ä½œç”¨ä¸æ˜æ˜¾ï¼ŒSigmoidè¾ƒä¸ºæ˜æ˜¾

```python
import torch
import torchvision
from torch import nn
from torch.nn import ReLU, Sigmoid
from torch.utils.data import Dataset, DataLoader


input = torch.tensor([[1, -0.5],
                     [-1, 3]])

# éœ€è¦æŒ‡å®šbatch_size
input = torch.reshape(input, (-1, 1, 2, 2))
print(input.shape)
# torch.Size([1, 1, 2, 2])
dataset = torchvision.datasets.CIFAR10("./dataset/CIFAR10", trian=False, download=True, transform=torchvision.transforms.ToTensor())
dataloader = DataLoader(dataset, batch_size=64)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.relu1 = ReLU()
        self.sigmoid1 = Sigmoid()
        
    def forward(self, input):
        output = self.sigmoid1(input)
        return output
    
tudui = Tudui()

step = 0
writer = SummaryWirter("./logs_sigmoid")
for data in dataloder:
    imgs, targets = data
    writer.add_images("input", imgs, step)
    output = tudui(imgs)
    writer.add_images("output", output, step)
    step = step + 1
    
writer.close()
```

åœ¨terminal ä¸­è¾“å…¥tensorboard --logdir=logs_sigmoid,ç‚¹å‡»è¾“å‡ºçš„ç«¯å£ï¼Œåœ¨å¼¹å‡ºçš„ç½‘é¡µä¸­å¯ä»¥çœ‹åˆ°è¾“å‡ºç»“æœ

![image-20251026230205939](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262302198.png)

![image-20251026230216048](https://typora3.oss-cn-shanghai.aliyuncs.com/202510262302341.png)

# 21-çº¿å½¢å±‚åŠå…¶ä»–å±‚ä»·ç»

## 21.1-æ­£åˆ™åŒ–å±‚

é‡‡ç”¨æ­£åˆ™åŒ–å±‚ï¼ˆç”¨çš„æ¯”è¾ƒå°‘ï¼‰å¯ä»¥æé«˜è®­ç»ƒé€Ÿåº¦

![image-20251027221318916](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272213327.png)

![image-20251027221409560](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272214708.png)

![image-20251027221421592](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272214764.png)

- num_features:å‰é¢æåˆ°çš„channelé€šé“æ•°

![image-20251027221542353](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272215519.png)

å°†è¾“å…¥æ”¾å…¥æ­£åˆ™åŒ–å±‚çš„ç½‘ç»œå½“ä¸­

## 21.2-Recurrentå±‚

ä¸»è¦ç”¨äºæ–‡å­—è¯†åˆ«çš„ç½‘ç»œç»“æ„ï¼Œç”¨çš„æ¦‚ç‡ä¸æ˜¯å¾ˆå¤š

![image-20251027221756496](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272217679.png)

## 21.3-Transformerå±‚

![image-20251027221823131](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272218313.png)

## 21.4-çº¿æ€§å±‚

![image-20251027221903887](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272219066.png)

![image-20251027221923153](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272219345.png)

![image-20251027222734071](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272227328.png)

ä¸Šå›¾ä¸­æ¯ä¸ªç¥ç»å…ƒä¹‹é—´é‡‡ç”¨çº¿æ€§è¿æ¥æ–¹å¼ï¼ŒInputLayer --- > Hidden Layerä¸­in_features=d   (åŒ…æ‹¬$x_1,x_2,...,x_d$)ï¼Œå¯¹åº”çš„out_features=L(åŒ…æ‹¬$g_1,g_2,...,g_L$)ï¼Œ$g_1$æ˜¯ç”±$x_1,x_2,...,x_d$è®¡ç®—å¾—åˆ°ï¼Œè®¡ç®—å…¬å¼æ˜¯$k_1 * x_1+b_1+k_2*x_2+b_2+...+k_d*x_d+b_d$,ç¥ç»ç½‘ç»œè®­ç»ƒä¸»è¦æ˜¯å¯¹$k_1, k_2, ..., k_d$è¿›è¡Œè°ƒæ•´

![image-20251027223251961](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272232159.png)

kï¼ˆæƒé‡ï¼‰å’Œbï¼ˆåç½®ï¼‰çš„åˆå§‹åŒ–ä¸»è¦æ˜¯ä»å‡åŒ€åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·

![image-20251027223448138](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272234307.png)

---

å‡è®¾æœ‰ä¸€å¼ 5*5å›¾ç‰‡ï¼Œå°†å…¶å±•æˆä¸€è¡Œï¼Œä¹Ÿå°±æ˜¯25ä¸ªï¼Œå°†è¿™25ä¸ªé€šè¿‡**çº¿æ€§å±‚**å˜ä¸º3ä¸ªå…ƒç´ 

![image-20251027223833766](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272238935.png)

åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè„šæœ¬nn_linear

```python
import torchvision

dataset = torchvision.datasets.CIFAR10("./dataset.CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=64, drop_last=true)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.Linear1 = Linear(3072, 10)
        
    def forward(self, input):
        output = self.linear1(input)
        return output
tudui = Tudui()

for data in dataloader:
    img, targets = data
    print(imgs.shape)
    # torch.Size([64, 3, 32, 32])
    # 3*32*32=3-72
    # æˆ‘ä»¬å°†å…¶æ‹‰ä¼¸ä¸ºä¸€ç»´å‘é‡
    output = torch.reshape(imgs, (64, 1, 1, -1))
    print(output.shape)
    # torch.Size([64, 1, 1, 3072])
    output = tudui(output)
    print(output.shape)

```



## 21.5-Dropout  å±‚

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¼šéšæœºå°†è¾“å…¥tensorçš„å…ƒç´ å˜ä¸º0ï¼Œéšæœºçš„æ¦‚ç‡ä¸ºpï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ

![image-20251027222131151](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272222303.png)

![image-20251027222143514](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272221696.png)

## 21.6-Sparseå±‚

ä¸»è¦ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ä¸­

![image-20251027222235084](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272222236.png)

## 21.7-Distance Functions

è®¡ç®—ä¸¤ä¸ªå€¼ä¹‹é—´çš„è¯¯å·®

![image-20251027222329845](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272223989.png)

## 21.8-Loss Functions

è®¡ç®—æŸå¤±å‡½æ•°

![image-20251027222421448](https://typora3.oss-cn-shanghai.aliyuncs.com/202510272224683.png)

......

# 22-æ­å»ºå°å®æˆ˜å’ŒSequentialçš„ä½¿ç”¨

- Sequentialï¼šå°†ç½‘ç»œç»“æ„æ”¾åœ¨Sequential()é‡Œé¢ï¼Œç„¶åmodel(input),ç»“æ„é‡Œé¢çš„é¡ºåºæ˜¯å…ˆå¯¹inputæ‰§è¡ŒConv2d(1, 20, 5)ï¼Œå†æ‰§è¡ŒReLU(),æ¥ç€æ‰§è¡ŒConv2d(20, 64, 5)ï¼Œ æœ€åæ‰§è¡ŒReLU()ï¼›

- å¥½å¤„ï¼šä»£ç å†™èµ·æ¥æ¯”è¾ƒç®€æ´ï¼Œä¹Ÿæ˜“æ‡‚

![image-20251028231659440](https://typora3.oss-cn-shanghai.aliyuncs.com/202510282316664.png)

CIFAR10 æ¨¡å‹

![image-20251029193726492](https://typora3.oss-cn-shanghai.aliyuncs.com/202510291937724.png)

- ç»è¿‡æœ€å¤§æ± åŒ–ï¼Œç§»åŠ¨æ ¼æ•°=kernel_size=2,æ¨ªå‘&çºµå‘éƒ½æ˜¯å‡åŠ
- ç¬¬ä¸€æ¬¡å·ç§¯åé€šé“æ•°å˜ä¸º32ï¼Œç”±äºå·ç§¯åŠ å…¥äº†paddingï¼Œ32ä¹Ÿæ˜¯è°ƒå‚è°ƒå‡ºæ¥çš„
  - å·ç§¯æ ¸çš„ç»´åº¦ã€5ï¼Œ5ï¼Œ3ï¼Œ 32ã€‘é‡‡ç”¨ 32ä¸ªå·ç§¯æ ¸ï¼Œå¤§å°ä¸º5*5ï¼Œ3æ˜¯è¾“å…¥å›¾åƒçš„é€šé“æ•°ï¼Œ32æ˜¯è¾“å‡ºå›¾åƒçš„é€šé“æ•°ï¼Œæ¯ä¸€ä¸ªå·ç§¯æ ¸çš„å°ºå¯¸ä¸º5x5x3ï¼ˆæœ€åçš„3å°±æ˜¯åŸå›¾çš„rgbé€šé“æ•°3ï¼‰ï¼Œæ¯ä¸€ä¸ªå·ç§¯æ ¸çš„æ¯ä¸€å±‚ï¼ˆ5x5ï¼‰ä¸åŸå›¾çš„æ¯ä¸€å±‚ï¼ˆ32x32ï¼‰ç›¸ä¹˜ï¼Œç„¶åå°†å¾—åˆ°çš„**ä¸‰å±‚**ç»“æœå¯¹åº”ä½ç½®å åŠ ï¼ˆç®—æœ¯æ±‚å’Œï¼‰ï¼Œå°±å¾—åˆ°è¿™ä¸ªç‚¹å¯¹åº”çš„å·ç§¯ç»“æœäº†ã€‚æ‰€æœ‰çš„ç‚¹å·ç§¯å®Œæˆä¹‹ååˆ™å¯ä»¥å¾—åˆ°ä¸€å¼ æ–°çš„feature map
- outputè®¾ç½®ä¸º10ï¼šç›¸å½“äºæ˜¯å¯¹MNISTæ•°æ®é›†è¿›è¡Œè¯†åˆ«

åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè„šæœ¬nn_Seq,é‡Œé¢ä¼šæ¶‰åŠåˆ°è®¡ç®— padding=2ï¼Œ stride=1(strideå€¼è¿‡å¤§ï¼Œpaddingçš„ä¼šå¾ˆå¤šï¼Œå½±å“å·ç§¯æ•ˆæœ)

![image-20251029202809730](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292028948.png)

> å‡è®¾ï¼š
>
> - è¾“å…¥å®½åº¦ï¼š$W_{in}$
> - å·ç§¯æ ¸å®½åº¦ï¼š$K$
> - æ­¥é•¿ï¼š$S$
>
> é‚£ä¹ˆå·ç§¯æ ¸æ¯æ¬¡æ»‘åŠ¨çš„èŒƒå›´æ˜¯ï¼š
> $$
> \text{ç¬¬ä¸€ä¸ªä½ç½®ï¼šè¦†ç›– [0, K-1]} \\
> \text{ç¬¬äºŒä¸ªä½ç½®ï¼šè¦†ç›– [S, S + K - 1]} \\
> \text{ç¬¬ä¸‰ä¸ªä½ç½®ï¼šè¦†ç›– [2S, 2S + K - 1]} \\
> \ldots
> $$
> å·ç§¯æ ¸èƒ½æ»‘åŠ¨çš„æœ€åä¸€ä¸ªä½ç½®æ˜¯åˆšå¥½ä¸è¶…è¿‡è¾“å…¥çš„æœ€å³ç«¯ï¼Œå³ï¼š
> $$
> nS + (K - 1) < W_{in}
> $$
> æ‰€ä»¥æœ€å¤§æ•´æ•° $n$ æ»¡è¶³ï¼š
> $$
> n = \left\lfloor \frac{W_{in} - (K-1)}{S} \right\rfloor
> $$
> è¾“å‡ºå®½åº¦æ˜¯ä½ç½®ä¸ªæ•° = $n + 1$ï¼Œäºæ˜¯ï¼š
> $$
> \boxed{W_{out} = \left\lfloor \frac{W_{in} - (K-1)}{S} \right\rfloor + 1}
> $$
>
> ------
>
> ## ğŸ§± ä¸‰ã€è€ƒè™‘ Paddingï¼ˆè¡¥é›¶ï¼‰
>
> å¦‚æœæˆ‘ä»¬åœ¨è¾“å…¥ä¸¤è¾¹å„è¡¥ä¸Š `padding` ä¸ªåƒç´ ï¼Œæ€»å…±å¤šäº† `2 Ã— padding` çš„å®½åº¦ã€‚
>
> äºæ˜¯æœ‰æ•ˆè¾“å…¥å®½åº¦å˜æˆï¼š
> $$
> W_{in}^{\text{eff}} = W_{in} + 2 \times padding
> $$
> ä»£å…¥åŸå…¬å¼ï¼š
> $$
> W_{out} = \left\lfloor \frac{W_{in} + 2 \times padding - (K-1)}{S} \right\rfloor + 1
> $$
>
> ------
>
> ## ğŸ§© å››ã€è€ƒè™‘ Dilationï¼ˆè†¨èƒ€å·ç§¯ï¼‰
>
> å½“ dilation > 1 æ—¶ï¼Œå·ç§¯æ ¸å†…éƒ¨å…ƒç´ ä¹‹é—´ä¼šâ€œæ’ç©ºâ€ï¼Œ
>  ä½¿å¾—å·ç§¯æ ¸çš„**æœ‰æ•ˆæ„Ÿå—é‡ï¼ˆè¦†ç›–èŒƒå›´ï¼‰**å˜å¤§ã€‚
>
> æœ‰æ•ˆå·ç§¯æ ¸å®½åº¦ï¼š
> $$
> K_{\text{eff}} = dilation \times (K - 1) + 1
> $$
> äºæ˜¯ï¼š
> $$
> W_{out} = \left\lfloor \frac{W_{in} + 2 \times padding - K_{\text{eff}}}{S} \right\rfloor + 1
> $$
> å±•å¼€ $K_{\text{eff}}$ï¼š
> $$
> \boxed{
> W_{out} = \left\lfloor
> \frac{W_{in} + 2 \times padding - dilation \times (K - 1) - 1}{S} + 1
> \right\rfloor
> }
> $$

ä¸Šä¸Šå›¾åœ¨Flattenå’ŒFully connected ä¸­é—´å°‘äº†ä¸ªå±•å¹³åçš„1024ï¼ˆ$64 * 4 * 4$ï¼‰,1024ä¸64ä¹‹é—´è¿˜æœ‰å…¨è¿æ¥å±‚ï¼ˆå¦‚é»„æ¡†æ‰€ç¤ºï¼‰,64 ä¸10ä¹‹é—´ä¹Ÿè¿˜æœ‰å…¨è¿æ¥å±‚ï¼ˆå¦‚é»„æ¡†æ‰€ç¤ºï¼‰

 ![image-20251029203457518](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292034759.png)

```python
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.conv1 = Conv2d(3, 32, 5, padding=2)
        self.maxpool1 = MaxPool2d(2)
        self.conv2 = Conv2d(32, 32, 5, padding=2)
        self.maxpool2 = MaxPool2d(2)
        self.conv3 = Conv2d(32, 64, 5, padding=2)
        self.maxpool3 = MaxPool2d(2)
        self.flatten = Flatten()
        self.Linear1 = Linear(1024, 64)
        self.Linear2 = Linear(64, 10)
    
    def forward(self, x):
        x = self.conv1(x)
        x = self.maxpool1(x)
        x = self.conv2(x)
        x = self.maxpool2(x)
        x = self.conv3(x)
        x = self.maxpool3(x)
        x = self.flatten(x)
        x = self.linear1(x)
        x = self.linear2(x)
        return x
     
tudui = Tudui()
print(tudui)   
# å†™å®Œæ£€æŸ¥ç½‘ç»œæ­£ç¡®æ€§ï¼Œä¸»è¦å»çœ‹è¾“å‡ºçš„å€¼æ˜¯å¦ç¬¦åˆè¦æ±‚
input = torch.ones(64, 3, 32, 32)
# è¡¨ç¤ºç”±64å¼ å›¾
output = tudui(input)
print(output.shape)
# torch.Size([64, 10])
```

![image-20251029203959035](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292039262.png)

```python
# å¼•å…¥Sequential
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        
        self.modle1 = Sequential(
            Conv2d(3, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        		
        )
    
    def forward(self, x):
        x = self.model1(x)
        return x
     
tudui = Tudui()
print(tudui)   
# å†™å®Œæ£€æŸ¥ç½‘ç»œæ­£ç¡®æ€§ï¼Œä¸»è¦å»çœ‹è¾“å‡ºçš„å€¼æ˜¯å¦ç¬¦åˆè¦æ±‚
input = torch.ones(64, 3, 32, 32)
# è¡¨ç¤ºç”±64å¼ å›¾
output = tudui(input)
print(output.shape)
# torch.Size([64, 10])
```

å¼•å…¥Sequential,ä»£ç ä¾¿ç®€æ´å¾ˆå¤š

```python
# å¼•å…¥tensorboardå¯è§†åŒ–
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential, Flatten, Linear
from torchvision import SummaryWriter

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        
        self.modle1 = Sequential(
            Conv2d(3, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        		
        )
    
    def forward(self, x):
        x = self.model1(x)
        return x
     
tudui = Tudui()
print(tudui)   
# å†™å®Œæ£€æŸ¥ç½‘ç»œæ­£ç¡®æ€§ï¼Œä¸»è¦å»çœ‹è¾“å‡ºçš„å€¼æ˜¯å¦ç¬¦åˆè¦æ±‚
input = torch.ones(64, 3, 32, 32)
# è¡¨ç¤ºç”±64å¼ å›¾
output = tudui(input)
print(output.shape)
# torch.Size([64, 10])

writer = SummaryWriter("../logs_seq")
writer.add_graph(tudui, input)# ç»˜åˆ¶è®¡ç®—å›¾
writer.close()
```

åœ¨terminal ä¸­è¾“å…¥tensorboard --logdir=logs_seq,ç‚¹å‡»è¾“å‡ºçš„ç«¯å£ï¼Œåœ¨å¼¹å‡ºçš„ç½‘é¡µä¸­å¯ä»¥çœ‹åˆ°è¾“å‡ºç»“æœ

![image-20251029205833017](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292058803.png)

![image-20251029205855738](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292058937.png)

![image-20251029205915263](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292059479.png)

ç»§ç»­ç‚¹å‡»Linear[7]

![image-20251029205949853](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292059035.png)

é»„è‰²æ¡†ä¼šæ˜¾ç¤ºé€åˆ°ç½‘ç»œä¸­æ•°æ®å°ºå¯¸çš„å¤§å°

![image-20251029210010286](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292100473.png)

# 23-æŸå¤±å‡½æ•°ä¸åå‘ä¼ æ’­

> æœ‰ä¸€å¼ è¯•å·ï¼Œé¢˜å‹ï¼šé€‰æ‹©ï¼ˆ30%ï¼‰ï¼Œå¡«ç©ºï¼ˆ20%ï¼‰ï¼Œ è§£ç­”ï¼ˆ50%ï¼‰ï¼Œæ»¡åˆ†100ï¼ˆtargetï¼‰ï¼Œå®é™…ä¸Šåªè€ƒäº†30åˆ†ï¼šé€‰æ‹©ï¼ˆ10â€˜ï¼‰ï¼Œå¡«ç©ºï¼ˆ10â€˜ï¼‰ï¼Œ è§£ç­”ï¼ˆ10â€˜ï¼‰ï¼ŒæŸå¤±å‡½æ•°è¡¡é‡å®é™…ä¸ç›®æ ‡ï¼ˆtargetï¼‰ä¹‹é—´çš„å·®è·ï¼Œè¿™è¾¹å°±æ˜¯$Loss=(30-10)+(20-10)+(50-10)=70$, å·®è·å¯ä»¥çŸ¥é“æŸå¤±å‡½æ•°ï¼ˆè§£ç­”éƒ¨åˆ†å¤ªå¼±äº†ï¼Œå¤šè®­ç»ƒè§£ç­”éƒ¨åˆ†ï¼‰å»æ¥è¿‘targetï¼ŒæŸå¤±å‡½æ•°å¤§å¤šæ•°æƒ…å†µä¸‹è¶Šå°è¶Šå¥½

æŸå¤±å‡½æ•°ä½œç”¨ï¼š

1. è®¡ç®—å®é™…è¾“å‡ºå’Œç›®æ ‡ä¹‹é—´çš„å·®è·ï¼›
2. ä¸ºæˆ‘ä»¬æ›´æ–°è¾“å‡ºæä¾›ä¸€å®šä¾æ®ï¼ˆåå‘ä¼ æ’­ï¼‰,ä¸ºæ¯ä¸€ä¸ªå·ç§¯æ ¸å‚æ•°ï¼ˆéœ€è¦è°ƒæ•´çš„uixï¼‰æä¾›æ¢¯åº¦å‚æ•°ï¼Œè¿›è€Œé™ä½lossï¼Œç±»ä¼¼æ¢¯åº¦ä¸‹é™æ³•

![image-20251029210715675](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292107974.png)

- nn.L1Loss:è®¡ç®—è¾“å‡ºä¸å…¶å¯¹åº”è¾“å‡ºçš„å·®å€¼ç»å¯¹å€¼ä¹‹å’Œï¼ˆä¹Ÿå¯ä»¥æ±‚å¹³å‡ï¼‰

  ![image-20251029210833343](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292108518.png)

  - æ³¨æ„è¾“å…¥å’Œè¾“å‡ºçš„shape

    ![image-20251029210949850](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292109049.png)

    - Nï¼šbatch_size

åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè„šæœ¬nn_loss

## L1LOSS

```python
import torch
from torch.nn import L1Loss

inputs = torch.tensor([1, 2, 3])
targets = torch.tensor([1, 2, 5])

inputs = torch.reshape(inputs, (1, 1, 1, 3))
targets = torch.reshape(targets, (1, 1, 1, 3))

loss = L1Loss()
result = Loss(inputs, targets)

print(result)
# ä¼šæŠ¥é”™ï¼šRuntimeError: Can only calculate the mean of floating types. Got Long instead.
```

```python
import torch
from torch.nn import L1Loss

inputs = torch.tensor([1, 2, 3], dtype=torch.float32)
targets = torch.tensor([1, 2, 5], dtype=torch.float32)

inputs = torch.reshape(inputs, (1, 1, 1, 3))
targets = torch.reshape(targets, (1, 1, 1, 3))

loss = L1Loss()
result = Loss(inputs, targets)

print(result)
# tensor(0.6667)
```

```python
# è®¾ç½®reductionå‚æ•°
import torch
from torch.nn import L1Loss

inputs = torch.tensor([1, 2, 3], dtype=torch.float32)
targets = torch.tensor([1, 2, 5], dtype=torch.float32)

inputs = torch.reshape(inputs, (1, 1, 1, 3))
targets = torch.reshape(targets, (1, 1, 1, 3))

loss = L1Loss(reduction='sum')
result = Loss(inputs, targets)

print(result)
# tensor(2.)
```

## å‡æ–¹è¯¯å·®

![image-20251029211906931](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292119201.png)

![image-20251029211916849](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292119071.png)

```python
import torch
from torch import nn

inputs = torch.tensor([1, 2, 3], dtype=torch.float32)
targets = torch.tensor([1, 2, 5], dtype=torch.float32)

inputs = torch.reshape(inputs, (1, 1, 1, 3))
targets = torch.reshape(targets, (1, 1, 1, 3))

loss_mse = nn.MSELoss()
result_mse = loss_mse(inputs, targets)

print(result_mse)
```

## äº¤å‰ç†µæŸå¤±å‡½æ•°

é€‚ç”¨äºåˆ†ç±»é—®é¢˜ï¼ˆå¤šåˆ†ç±»& åŒåˆ†ç±»ï¼‰

![image-20251029220556370](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292205676.png)

![image-20251029222356580](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292223795.png)

- C:ç±»åˆ«æ•°

---

æœ‰ä¸€ä¸ªä¸‰åˆ†ç±»é—®é¢˜ï¼šPersonï¼Œ dog, cat,ç°åœ¨æœ‰ä¸€ç§ç‹—çš„å›¾ç‰‡ï¼Œè¿˜æœ‰ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œä¼šè¾“å‡ºä¸€ä¸ªæ¦‚ç‡ã€0.1ï¼Œ 0.2ï¼Œ 0.3ã€‘ï¼ˆäº¤å‰ç†µä¸­æ¦‚ç‡å’Œä¸ä¸€å®šç­‰äº1ï¼Œæ¦‚ç‡å¯ä»¥çœ‹æˆä¸‹ä¸‹å›¾ç¥ç»ç½‘ç»œè¾“å‡ºç»“æœï¼Œè¿™è¾¹$y_i=1$ï¼‰ï¼Œè®¡ç®—loss

![image-20251029221053971](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292210288.png)

![image-20251029221857212](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292218565.png)

![image-20251029221907256](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292219642.png)

```python
from torch import nn

x = torch.tensor([0.1, 0.2, 0.3])# ç¥ç»ç½‘ç»œè¾“å‡ºå€¼
y = torch.tensor([1])# ä¸‹ä¸ªä¾‹å­ä¸­targetå€¼
x = torch.reshape(x, (1, 3))
loss_cross = nn.CrossEntropyLoss()
result_cross = loss_cross(x, y)
print(result_cross)
# tensor(1.1019)

```

åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè„šæœ¬nn_loss_network

```python
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential, Flatten, Linear
from torchvision import SummaryWriter

dataset = torchvision.datasets.CIFAR10("./data.CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=1)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        
        self.modle1 = Sequential(
            Conv2d(3, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        		
        )
    
    def forward(self, x):
        x = self.model1(x)
        return x
    
tudui = Tudui()
for data in dataloader:
    img, targets = data
    ouutputs = tudui(imgs)
    print(outputs)
    print(targets)
    
```

![image-20251029224433632](https://typora3.oss-cn-shanghai.aliyuncs.com/202510292244864.png)

```python
# åŠ å…¥å«äº¤å‰ç†µæŸå¤±
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential, Flatten, Linear
from torchvision import SummaryWriter

dataset = torchvision.datasets.CIFAR10("./data.CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=1)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        
        self.modle1 = Sequential(
            Conv2d(3, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        		
        )
    
    def forward(self, x):
        x = self.model1(x)
        return x

loss = nn.CrossEntrophyLoss()
tudui = Tudui()
for data in dataloader:
    img, targets = data
    ouutputs = tudui(imgs)
    result_loss = loss(outputs, targets)
    
```

åå‘ä¼ æ’­ï¼šä¸ºæ¯ä¸€ä¸ªå·ç§¯æ ¸å‚æ•°ï¼ˆéœ€è¦è°ƒæ•´çš„å¯¹è±¡ï¼‰æä¾›æ¢¯åº¦å‚æ•°ï¼Œè¿›è€Œé™ä½lossï¼Œç±»ä¼¼æ¢¯åº¦ä¸‹é™æ³•

```python
# åŠ å…¥åå‘ä¼ æ’­
import torchvision
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential, Flatten, Linear
from torchvision import SummaryWriter
from torch.utils.data import DataLoader

dataset = torchvision.datasets.CIFAR10("./data.CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=1)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        
        self.modle1 = Sequential(
            Conv2d(3, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        		
        )
    
    def forward(self, x):
        x = self.model1(x)
        return x

loss = nn.CrossEntrophyLoss()
tudui = Tudui()
for data in dataloader:
    img, targets = data
    ouutputs = tudui(imgs)
    result_loss = loss(outputs, targets)
    result_loss.backward()
    print("ok")
    # å¯ä»¥dubugæŸ¥çœ‹å˜é‡åˆ—è¡¨ä¸‹tudui--model1--Protected Attributes--_modules--'0'--weight--grad
    # weightä¸‹æ‹‰ä¸­çš„dataæ˜¯æŒ‡weightå€¼
    # ä¸€å¼€å§‹gradçš„å€¼åº”è¯¥ä¸ºNone
    # æ¯ä¸€æ¬¡è¿è¡Œéƒ½ä¼šå¯¹gradå€¼è¿›è¡Œæ›´æ–°
    # å¦‚æœæ²¡æœ‰result_loss.backward()ï¼Œåˆ™ä¸ä¼šå¯¹gradè¿›è¡Œæ›´æ–°
```

# 24-ä¼˜åŒ–å™¨

é€šè¿‡å®˜æ–¹æ–‡æ¡£æ¥å­¦ä¹ 

- SGD/Adamï¼šä¼˜åŒ–å™¨ç®—æ³•
- lr:å­¦ä¹ ç‡ï¼ˆlearning_rateï¼‰

![image-20251030201314951](https://typora3.oss-cn-shanghai.aliyuncs.com/202510302013303.png)

- step:åˆ©ç”¨è®¡ç®—çš„å‚æ•°æ¢¯åº¦å¯¹å‚æ•°è¿›è¡Œæ›´æ–°è°ƒæ•´
- `optimizer.zero_grad()`:å¯¹åå‘ä¼ æ’­è®¡ç®—çš„æ¢¯åº¦è¿›è¡Œæ¸…é›¶ï¼Œä¸Šæ¬¡è®¡ç®—çš„æ¢¯åº¦å¯¹ä¸‹æ¬¡çš„æ¢¯åº¦è®¡ç®—æ²¡æœ‰æ„ä¹‰ï¼ˆå¦‚è‹¥ä¸æ˜¾ç¤ºçš„è¿›è¡Œ[optimizer.zero_grad()](https://zhida.zhihu.com/search?content_id=134342210&content_type=Answer&match_order=1&q=optimizer.zero_grad()&zhida_source=entity)è¿™ä¸€æ­¥æ“ä½œï¼Œbackward()çš„æ—¶å€™å°±ä¼šç´¯åŠ æ¢¯åº¦ï¼‰

![image-20251030201439241](https://typora3.oss-cn-shanghai.aliyuncs.com/202510302014512.png)

![image-20251030201759641](https://typora3.oss-cn-shanghai.aliyuncs.com/202510302017861.png)

åé¢ä¸åŒçš„ç®—æ³•ï¼Œå‚æ•°ç›¸åŒçš„åªæœ‰paramså’Œlr

åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè„šæœ¬nn_optim

```python
import torchvision
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential, Flatten, Linear
from torchvision import SummaryWriter
from torch.utils.data import DataLoader

dataset = torchvision.datasets.CIFAR10("./data.CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=1)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        
        self.modle1 = Sequential(
            Conv2d(3, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        		
        )
    
    def forward(self, x):
        x = self.model1(x)
        return x

loss = nn.CrossEntrophyLoss()
tudui = Tudui()
# è®¾ç½®ä¼˜åŒ–å™¨
optim = torch.optim.SGD(tudui.parameteers(), lr=0.01)#éšæœºæ¢¯åº¦ä¸‹é™
# å­¦ä¹ é€Ÿç‡ä¸€å¼€å§‹è®¾ç½®çš„è¾ƒå¤§ä¸€ç‚¹ï¼Œç­‰åˆ°è®­ç»ƒåæœŸå†å°†å…¶å˜å°
for data in dataloader:
    img, targets = data
    ouutputs = tudui(imgs)
    result_loss = loss(outputs, targets)
    optim.zero_grad()
    result_loss.backward()
    optim.step()
```

```python
# è¿›è¡Œå¤šè½®è®­ç»ƒ
import torchvision
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential, Flatten, Linear
from torchvision import SummaryWriter
from torch.utils.data import DataLoader

dataset = torchvision.datasets.CIFAR10("./data.CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=1)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        
        self.modle1 = Sequential(
            Conv2d(3, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        		
        )
    
    def forward(self, x):
        x = self.model1(x)
        return x

loss = nn.CrossEntrophyLoss()
tudui = Tudui()
# è®¾ç½®ä¼˜åŒ–å™¨
optim = torch.optim.SGD(tudui.parameteers(), lr=0.01)#éšæœºæ¢¯åº¦ä¸‹é™
# å­¦ä¹ é€Ÿç‡ä¸€å¼€å§‹è®¾ç½®çš„è¾ƒå¤§ä¸€ç‚¹ï¼Œç­‰åˆ°è®­ç»ƒåæœŸå†å°†å…¶å˜å°
for epoch in range(20):
    running_loss = 0
    for data in dataloader:
        img, targets = data
        ouutputs = tudui(imgs)
        result_loss = loss(outputs, targets)
        optim.zero_grad()
        result_loss.backward()
        optim.step()
        running_loss = running_loss + result_loss
    print(running_loss)
```

æ¯ä¸€è½®çš„losséƒ½åœ¨ä¸æ–­å‡å°

![image-20251030204026423](https://typora3.oss-cn-shanghai.aliyuncs.com/202510302040649.png)

# 25-ç°æœ‰ç½‘ç»œæ¨¡å‹çš„ä½¿ç”¨åŠä¿®æ”¹

## VGG

å¸¸ç”¨çš„æ˜¯VGG16(ImagNet:15000å¼ å›¾ç‰‡ï¼Œ1000ç±»çš„åˆ†ç±»æ•°æ®é›†ï¼›)ï¼ŒVGG19ï¼š

- pretrainedï¼šå¦‚æœä¸ºTrueï¼Œæ¨¡å‹å‚æ•°åœ¨ImageNetæ•°æ®é›†ä¸­å·²ç»è®­ç»ƒå¥½äº†ï¼Œå·²ç»å–å¾—å¾ˆå¥½çš„æ•ˆæœï¼›å¦‚æœä¸ºFalseï¼Œå‚æ•°å€¼ä¸ºåˆå§‹åŒ–å‚æ•°ï¼Œæ²¡æœ‰åœ¨æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒ
- progressï¼šæ˜¯å¦ç”Ÿæˆè¿›åº¦æ¡

![image-20251030205149481](https://typora3.oss-cn-shanghai.aliyuncs.com/202510302051699.png)

![image-20251030205231157](https://typora3.oss-cn-shanghai.aliyuncs.com/202510302052379.png)

> éœ€è¦æŒ‰ä½scipyåŒ…

åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè„šæœ¬model_pretrained

> åœ¨terminalä¸­æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼Œæ£€éªŒæ˜¯å¦å®‰è£…åŒ…ï¼š`pip list`ï¼Œå¦‚æœæ²¡æœ‰ï¼Œå®‰è£…scipyï¼š`pip install scipy`

```python
train_data = torchvision.datasets.ImageNet("./dataset/ImageNet", split="train", download=True, transform=torchvision.transform.ToTensor())# éœ€è¦è®­ç»ƒé›†
# ä¼šæŠ¥é”™ï¼šéœ€è¦æ‰‹åŠ¨å®‰è£…
# è¿™ä¸ªæ•°æ®é›†æœ‰149Gib
```

```python
# åŠ è½½ç½‘ç»œç»“æ„
import torchvision
vgg16_false = torchvision.models.vgg16(pretrained=False)
# è®°è½½ç½‘ç»œæ¨¡å‹åƒçš„å‚æ•°æ˜¯åˆå§‹åŒ–çš„
vgg16_true = torchvision.models.vgg16(pretrained=True)
# ä»ç½‘ç»œä¸­ä¸‹è½½å…·ä½“å‚æ•°ï¼šæ± åŒ–å±‚çš„å…·ä½“å‚æ•°å·²ç»åœ¨æ•°æ®é›†ä¸Šè®­ç»ƒå¥½çš„
# æ–­ç‚¹è°ƒè¯•ï¼šç‚¹å‡»vgg16_true--features--Protected Attributes--_modules--'0'--weight
```

vgg16_trueçš„ç½‘ç»œç»“æ„

![image-20251030210451103](https://typora3.oss-cn-shanghai.aliyuncs.com/202510302104376.png)

vgg16_falseçš„ç½‘ç»œç»“æ„

![image-20251030210613546](https://typora3.oss-cn-shanghai.aliyuncs.com/202510302106781.png)

>  ä¸¤è€…å·®åˆ«ä¸å¤§

```python
print(vgg16_true)
# VGG16ï¼š1000åˆ†ç±»çš„åˆ†ç±»çš„åˆ†ç±»æ¨¡å‹
```

![image-20251030210745436](https://typora3.oss-cn-shanghai.aliyuncs.com/202510302107706.png)

![image-20251030211231071](https://typora3.oss-cn-shanghai.aliyuncs.com/202510302112304.png)

```python
train_data = torchvision.datasets.CIFAR10("./dataset/CIFAR10", train=True, transform=trochvision.transforms.ToTensor(), download=True)
# CIFAR10æ˜¯10åˆ†ç±»çš„æ•°æ®é›†ï¼Œéœ€è¦å¥—VGG16çš„ç½‘ç»œç»“æ„ï¼Œéœ€è¦å°†outfeaturesä¿®æ”¹ä¸º10ï¼Œæˆ–è€…å†åœ¨åé¢å¥—ä¸€å±‚çº¿æ€§å±‚è¾“å‡ºç‰¹å¾æ•°ä¸º10, è¾“å…¥ç‰¹å¾æ•°ä¸º1000

```

```python
# åˆ©ç”¨ç°æœ‰ç½‘ç»œè¿›è¡Œæ­å»º:å°†outfeaturesä¿®æ”¹ä¸º10ï¼ˆå¾ˆå¤šçš„ç»“æ„ä¹Ÿéƒ½æ˜¯åœ¨VGGçš„åé¢åŠ ä¸Šä¸€äº›å…¶ä»–çš„å±‚ï¼‰
from torch import nn
vgg16_true.add_module("add_linear", nn.Linear(1000, 10))
# æ­¤æ—¶çš„çº¿æ€§å±‚æ˜¯åŠ åœ¨classifierçš„å¤–é¢ï¼Œæˆ‘ä»¬éœ€è¦åŠ åœ¨classifierçš„é‡Œé¢

vgg16_true.classifier.add_module("add_linear", nn.Linear(1000, 10))
```

```python
# ç›´æ¥ä¿®æ”¹VGG16çš„æœ€åä¸€å±‚linear_layer
# ç”±äºvgg16_trueå·²ç»ä½¿ç”¨è¿‡äº†ï¼Œè¿™é‡Œä½¿ç”¨vgg16_false
vgg16_false.classifier[6] = nn.Linear(4096, 10)
print(vgg16_false)
```

![image-20251030212031547](https://typora3.oss-cn-shanghai.aliyuncs.com/202510302120777.png)

# 26-ç½‘ç»œæ¨¡å‹çš„ä¿å­˜ä¸è¯»å–

åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè„šæœ¬model_save

```python
import torchvision, torch
vgg16 = torchvision.models.vgg16(pretrained=False)
# ä¿å­˜æ–¹å¼1
torch.save(vgg16, "vgg16_method1.pth")
# "vgg16_method1.pth":ä¿å­˜è·¯å¾„
# æ­¤æ—¶ä¸ä»…ä¿å­˜äº†ç½‘ç»œæ¨¡å‹ï¼Œä¹Ÿä¿å­˜äº†æ¨¡å‹å‚æ•°

# åŠ è½½æ¨¡å‹æ–¹å¼1
model = torch.load("vgg16_method1.pth")
print(mdoel)

# ä¿å­˜æ–¹å¼2:æ¨¡å‹å‚æ•°ï¼ˆå®˜æ–¹æ¨èï¼‰
torch.save(vgg16.state_dict(), "vgg16_method2.pth")# å°†vggçš„çŠ¶æ€ä¿å­˜ä¸ºå­—å…¸æ ¼å¼
# åŠ è½½æ¨¡å‹æ–¹å¼2
model = torch.load("vgg16_method2.pth")
print(model)
```

æ–¹å¼2æ‰“å°çš„æ˜¯å­—å…¸å½¢å¼

![image-20251030214603203](https://typora3.oss-cn-shanghai.aliyuncs.com/202510302146419.png)

> æŸ¥çœ‹æ¨¡å‹æ–‡ä»¶å¤§å°ï¼š
>
> åœ¨terminalä¸­cd åˆ°æŒ‡å®šçš„æ–‡ä»¶å¤¹ï¼Œç„¶åè¾“å…¥`ls -all`(mac),`dir`(win)

```python
# å°†å­—å…¸å½¢å¼æ¢å¤æˆç½‘ç»œç»“æ„
vgg16 = torchvision.models.vgg16(pretrained=False)
vgg16.load_state_dict(torch.load("vgg16_method2.pth"))
# é€šè¿‡å­—å…¸å½¢å¼è·å–vgg16çš„ç½‘ç»œç»“æ„
print(vgg16)
```

---

```python
# é™·é˜±ï¼ˆå†™åœ¨å¦ä¸€ä¸ªpythonæ–‡ä»¶model_save2é‡Œï¼‰
from torch import nn
import torch

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3)
        
    def forward(self, x):
        x = self.conv1(x)
        return x

tudui = Tudui()
torch.save(tudui, "tudui_method1.pth")     
        
```

```python
# å†™åœ¨model_saveè„šæœ¬é‡Œ
model = torch.load("tudui_method1.pth")
print(model)
#ä¼šæŠ¥é”™: Can't get attribute 'Tudui' on <module '__main__'from ....

# æ­¤æ—¶éœ€è¦å°†ä¸Šé¢åˆ›å»ºçš„ç±»æ”¾åœ¨ä¸Šé¢ï¼Œä½†æ˜¯ä¸éœ€è¦åˆå§‹åŒ–å®ä¾‹
```

```python
from torch import nn

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3)
        
    def forward(self, x):
        x = self.conv1(x)
        return x

model = troch.load("tudui_method1.pth")
print(model)
# æˆ–è€…from model_save2 impor *
```

```python
from torch import nn
from model_save2 impor *

model = troch.load("tudui_method1.pth")
print(model)
# æˆ–è€…import Tuidui
```



# 27-å®Œæ•´çš„æ¨¡å‹è®­ç»ƒ

> ä»¥CIFAR10æ•°æ®é›†ä¸ºä¾‹å­
>
> ![image-20251029203457518](https://typora3.oss-cn-shanghai.aliyuncs.com/202510302235940.png)

åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè„šæœ¬mdoel

```python
# model.py
# æ­å»ºç¥ç»ç½‘ç»œï¼ˆ10åˆ†ç±»ï¼‰
import torch
from torch import nn

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.model = nn.Sequential(
        	nn.Conv2d(3, 32, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 32, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Linear(64*4*4, 64),
            nn.Linear(64, 10),
        )
        
    def forward(self, x):
        x = self.model(x)
        return x

if __name__ == "__main__":
    tudui = Tudui()
    # éªŒè¯ç½‘ç»œçš„æ­£ç¡®æ€§ï¼šä¸»è¦çœ‹è¾“å‡ºçš„å°ºå¯¸
    input = torch.ones((64, 3, 32, 32))
    output = tudui(input)
    print(output.shape)
    # torch.Size([64, 10])
```

åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè„šæœ¬train(è¦è·Ÿmodelåœ¨åŒä¸€æ ¹ç›®å½•ä¸‹)

```python
import torchvision
from torch.utils.datya import DataLoader
from torch import nn
from model import *

# å‡†å¤‡æ•°æ®é›†
train_data = torchvision.datasets.CIFAR10(root="./dataset/CIFAR10", train=True, transform=torchvision.transforms.ToTensor(), download=True)
test_data = torchvision.datasets.CIFAR10(root="./dataset/CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
# æŸ¥çœ‹æ•°æ®é›†å¤§å°
train_data.size = len(train_data)
test_data.size = len(test_data)
print("è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š{}".format(train_data.size))
# è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š50000
# å°†å…‰æ ‡æ”¾åœ¨ä¸Šä¸€è¡Œä»£ç çš„å°¾éƒ¨ï¼ŒæŒ‰ä¸‹Ctrl+D,å®ç°å¯¹ä¸Šä¸€è¡Œä»£ç çš„å¤åˆ¶
print("è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š{}".format(train_data.size))
# è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š10000

# åˆ©ç”¨DataLoaderæ¥åŠ è½½æ•°æ®é›†
train_dataLoader = DataLoder(train_data, batch_size=64)
test_datalaoder = DataLoder(test_data, batch_size=64)

# åˆ›å»ºç½‘è·¯æ¨¡å‹
tudui = Tudui()

# æŸå¤±å‡½æ•°
loss_fn = nn.CrossEntropyLoss()

# ä¼˜åŒ–å™¨
learning_rate = 0.01# æ–¹ä¾¿ä¿®æ”¹ï¼Œä¹Ÿå¯ä»¥å†™æˆ1e-2
optimizer = torch.optim.SGD(tudui.parameters(), lr=learning_rate, )

# è®¾ç½®è®­ç»ƒç½‘ç»œçš„ä¸€äº›å‚æ•°
total_train_step = 0	# è®°å½•è®­ç»ƒæ¬¡æ•°
total_test_step = 0		# è®°å½•æµ‹è¯•æ¬¡æ•°
epoch = 10		# è®­ç»ƒæ¬¡æ•°

for i in range(epoch):
    print("------------------ç¬¬ {} è½®è®­ç»ƒå¼€å§‹-----------------".format(i+1))
    # è®­ç»ƒæ­¥éª¤å¼€å§‹
    for data in train_dataLoader:
        imgs, targets = data
        outputs = tudui(imgs)
        loss = loss_fn(outputs, targets)
        # ä¼˜åŒ–å™¨ä¼˜åŒ–æ¨¡å‹
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_train_step = total_train_step + 1
        print("è®­ç»ƒæ¬¡æ•°ï¼š{}ï¼ŒLoss:{}".format(total_train_step, loss.item()))
        # loss.item()è§scratch.pyçš„è¾“å‡º
        
    
```

åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè‰ç¨¿è„šæœ¬scratch.py

```python
import torch

a = torch.tensor(5)
print(a)
# tensor(5)
print(a.item())
# 5
```

æ£€éªŒæ¯è½®æ¨¡å‹è®­ç»ƒç»“æŸåæ˜¯å¦è¾¾åˆ°éœ€æ±‚ï¼Œæ˜¯å¦è®­ç»ƒåï¼Œæ­¤æ—¶å°±ä¸éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œè°ƒä¼˜ï¼ˆä¸éœ€è¦è®¡ç®—æ¢¯åº¦è°ƒä¼˜ï¼Œæé«˜æ¨¡å‹æ¨ç†é€Ÿåº¦ï¼‰

```python
import torchvision
from torch.utils.datya import DataLoader
from torch import nn
from model import *

# å‡†å¤‡æ•°æ®é›†
train_data = torchvision.datasets.CIFAR10(root="./dataset/CIFAR10", train=True, transform=torchvision.transforms.ToTensor(), download=True)
test_data = torchvision.datasets.CIFAR10(root="./dataset/CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
# æŸ¥çœ‹æ•°æ®é›†å¤§å°
train_data.size = len(train_data)
test_data.size = len(test_data)
print("è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š{}".format(train_data.size))
# è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š50000
# å°†å…‰æ ‡æ”¾åœ¨ä¸Šä¸€è¡Œä»£ç çš„å°¾éƒ¨ï¼ŒæŒ‰ä¸‹Ctrl+D,å®ç°å¯¹ä¸Šä¸€è¡Œä»£ç çš„å¤åˆ¶
print("è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š{}".format(train_data.size))
# è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š10000

# åˆ©ç”¨DataLoaderæ¥åŠ è½½æ•°æ®é›†
train_dataLoader = DataLoder(train_data, batch_size=64)
test_datalaoder = DataLoder(test_data, batch_size=64)

# åˆ›å»ºç½‘è·¯æ¨¡å‹
tudui = Tudui()

# æŸå¤±å‡½æ•°
loss_fn = nn.CrossEntropyLoss()

# ä¼˜åŒ–å™¨
learning_rate = 0.01# æ–¹ä¾¿ä¿®æ”¹ï¼Œä¹Ÿå¯ä»¥å†™æˆ1e-2
optimizer = torch.optim.SGD(tudui.parameters(), lr=learning_rate, )

# è®¾ç½®è®­ç»ƒç½‘ç»œçš„ä¸€äº›å‚æ•°
total_train_step = 0	# è®°å½•è®­ç»ƒæ¬¡æ•°
total_test_step = 0		# è®°å½•æµ‹è¯•æ¬¡æ•°
epoch = 10		# è®­ç»ƒæ¬¡æ•°

for i in range(epoch):
    print("------------------ç¬¬ {} è½®è®­ç»ƒå¼€å§‹-----------------".format(i+1))
    # è®­ç»ƒæ­¥éª¤å¼€å§‹
    for data in train_dataLoader:
        imgs, targets = data
        outputs = tudui(imgs)
        loss = loss_fn(outputs, targets)
        # ä¼˜åŒ–å™¨ä¼˜åŒ–æ¨¡å‹
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_train_step = total_train_step + 1
        # ä¸è®©ä»–æ¯æ¬¡éƒ½æ‰“å°(é€¢100æ‰æ‰“å°)
        if total_traib_step % 100 == 0:
          print("è®­ç»ƒæ¬¡æ•°ï¼š{}ï¼ŒLoss:{}".format(total_train_step, loss.item()))
          # loss.item()è§scratch.pyçš„è¾“å‡º
        
    # æµ‹è¯•æ­¥éª¤å¼€å§‹
    total_test_loss = 0
    with torch.no_grad():
      for data in test_dataloader:
        img,  targets = data
        outputs = tudui(imgs)
        loss = loss_fn(outputs)
        total_test_loss = total_test_loss + loss.item()
    print("æ•´ä½“æµ‹è¯•é›†ä¸Šçš„Loss:{}".format(total_test_loss))
        
```



ç»“æœè¿›è¡Œå¯è§†åŒ–

```python
import torchvision
from torch.utils.datya import DataLoader
from torch import nn
from model import *
from torch.utils.tensorboard import SummaryWriter

# å‡†å¤‡æ•°æ®é›†
train_data = torchvision.datasets.CIFAR10(root="./dataset/CIFAR10", train=True, transform=torchvision.transforms.ToTensor(), download=True)
test_data = torchvision.datasets.CIFAR10(root="./dataset/CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
# æŸ¥çœ‹æ•°æ®é›†å¤§å°
train_data.size = len(train_data)
test_data.size = len(test_data)
print("è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š{}".format(train_data.size))
# è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š50000
# å°†å…‰æ ‡æ”¾åœ¨ä¸Šä¸€è¡Œä»£ç çš„å°¾éƒ¨ï¼ŒæŒ‰ä¸‹Ctrl+D,å®ç°å¯¹ä¸Šä¸€è¡Œä»£ç çš„å¤åˆ¶
print("è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š{}".format(train_data.size))
# è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š10000

# åˆ©ç”¨DataLoaderæ¥åŠ è½½æ•°æ®é›†
train_dataLoader = DataLoder(train_data, batch_size=64)
test_datalaoder = DataLoder(test_data, batch_size=64)

# åˆ›å»ºç½‘è·¯æ¨¡å‹
tudui = Tudui()

# æŸå¤±å‡½æ•°
loss_fn = nn.CrossEntropyLoss()

# ä¼˜åŒ–å™¨
learning_rate = 0.01# æ–¹ä¾¿ä¿®æ”¹ï¼Œä¹Ÿå¯ä»¥å†™æˆ1e-2
optimizer = torch.optim.SGD(tudui.parameters(), lr=learning_rate, )

# è®¾ç½®è®­ç»ƒç½‘ç»œçš„ä¸€äº›å‚æ•°
total_train_step = 0	# è®°å½•è®­ç»ƒæ¬¡æ•°
total_test_step = 0		# è®°å½•æµ‹è¯•æ¬¡æ•°
epoch = 10		# è®­ç»ƒæ¬¡æ•°

# æ·»åŠ tensorboard
writer = SummaryWriter("./logs_train")

for i in range(epoch):
    print("------------------ç¬¬ {} è½®è®­ç»ƒå¼€å§‹-----------------".format(i+1))
    # è®­ç»ƒæ­¥éª¤å¼€å§‹
    for data in train_dataLoader:
        imgs, targets = data
        outputs = tudui(imgs)
        loss = loss_fn(outputs, targets)
        # ä¼˜åŒ–å™¨ä¼˜åŒ–æ¨¡å‹
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_train_step = total_train_step + 1
        # ä¸è®©ä»–æ¯æ¬¡éƒ½æ‰“å°(é€¢100æ‰æ‰“å°)
        if total_traib_step % 100 == 0:
          print("è®­ç»ƒæ¬¡æ•°ï¼š{}ï¼ŒLoss:{}".format(total_train_step, loss.item()))
          
          writer.add_scalar("train_loss", loss.item(), total_train_step)
        
    # æµ‹è¯•æ­¥éª¤å¼€å§‹
    total_test_loss = 0
    with torch.no_grad():
        # torch.no_grad() ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€šå¸¸ç”¨äºé‚£äº›ä¸éœ€è¦è®¡ç®—æ¢¯åº¦çš„æ“ä½œï¼Œä¾‹å¦‚åœ¨æ¨¡å‹è¯„ä¼°æˆ–æ¨æ–­æ—¶ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œå…³é—­è‡ªåŠ¨æ±‚å¯¼åŠŸèƒ½å¯ä»¥æé«˜ä»£ç æ‰§è¡Œæ•ˆç‡ï¼Œå› ä¸ºä¸éœ€è¦è®¡ç®—æ¢¯åº¦çš„æ“ä½œé€šå¸¸æ¯”éœ€è¦è®¡ç®—æ¢¯åº¦çš„æ“ä½œæ›´å¿«ã€‚
      for data in test_dataloader:
        img,  targets = data
        outputs = tudui(imgs)
        loss = loss_fn(outputs)
        total_test_loss = total_test_loss + loss.item()
    print("æ•´ä½“æµ‹è¯•é›†ä¸Šçš„Loss:{}".format(total_test_loss))
    writer.add_scalar("test_loss", total_test_loss, total_test_step)
    total_test_step = total_test_step +  1
    # ä¿å­˜æ¯ä¸€è½®è®­ç»ƒçš„æˆæœ
    torch.save(tudui, "tudui_{}.pth".fprmat(i))
    print("æ¨¡å‹å·²ä¿å­˜")

writer.close()
      
        
```

åœ¨terminal ä¸­æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼Œè¾“å…¥tensorboard --logdir=logs_train,ç‚¹å‡»è¾“å‡ºçš„ç«¯å£ï¼Œåœ¨å¼¹å‡ºçš„ç½‘é¡µä¸­å¯ä»¥çœ‹åˆ°è¾“å‡ºç»“æœ

![image-20251101150111203](https://typora-alex2.oss-cn-shanghai.aliyuncs.com/202511011501410.png)

æµ…è‰²çš„çº¿æ‰æ˜¯çœŸå®å€¼ï¼›æ·±è‰²çº¿æ˜¯åŠ å…¥å¹³æ»‘ç³»æ•°åçš„å€¼

---

åˆ†ç±»é—®é¢˜è®¡ç®—æ•´ä½“çš„æ­£ç¡®ç‡

æœ‰ä¸¤ä¸ªè¾“å…¥ï¼Œå°†å…¶æ”¾å…¥æ¨¡å‹ä¸­ï¼ˆäºŒåˆ†ç±»æ¨¡å‹ï¼‰ï¼Œç¬¬ä¸€ä¸ªè¾“å…¥å¯¹åº”çš„è¾“å‡ºå¾—åˆ†ã€0.1ï¼Œ 0.2ã€‘ï¼Œç¬¬ä¸€ä¸ªè¾“å…¥å¯¹åº”çš„è¾“å‡ºå¾—åˆ†ã€0.3ï¼Œ 0.4ã€‘ï¼Œå‰ä¸€ä¸ªå€¼å¯¹åº”ç±»åˆ«0ï¼Œåä¸€ä¸ªå€¼å¯¹åº”çš„æ˜¯ç±»åˆ«1 ï¼ˆç”¨äº†softmaxå’Œä¼šå˜æˆ1å§ï¼ŒåŸç”Ÿçš„é¢„æµ‹åº”è¯¥æ˜¯æ•°å€¼åŒ–çš„ï¼Œä¸ä¸€å®šæ˜¯æ¦‚ç‡ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦å°†argmaxå°†å…¶è¾“å‡ºè½¬åŒ–ä¸ºç±»åˆ«å€¼

![image-20251101150901251](https://typora-alex2.oss-cn-shanghai.aliyuncs.com/202511011509290.png)

åˆ©ç”¨Preds == targetï¼Œä»¥åŠ`[false, true].sum()`æ¥è®¡ç®—åˆ†ç±»å‡†ç¡®æ€§

åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè„šæœ¬test2.py

```python
import torch
outputs = torch.tensor([[0.1, 0.2],
                         [0.3, 0.4]
  
])
print(outputs.argmax(axis=1))# ä»axis=1 çš„æ–¹å‘çœ‹æ¯è¡Œæœ€å¤§å€¼çš„çš„indexä½ç½®
# tensor([1, 1])
preds = outputs.argmaxn(1)
targets = torch.tensor([0, 1])
print(preds == targets)
# tensor([False, True])
print((preds == targets).sum())
# tensor(1)
```

```python
# train.py
import torchvision
from torch.utils.datya import DataLoader
from torch import nn
from model import *
from torch.utils.tensorboard import SummaryWriter

# å‡†å¤‡æ•°æ®é›†
train_data = torchvision.datasets.CIFAR10(root="./dataset/CIFAR10", train=True, transform=torchvision.transforms.ToTensor(), download=True)
test_data = torchvision.datasets.CIFAR10(root="./dataset/CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
# æŸ¥çœ‹æ•°æ®é›†å¤§å°
train_data.size = len(train_data)
test_data.size = len(test_data)
print("è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š{}".format(train_data.size))
# è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š50000
# å°†å…‰æ ‡æ”¾åœ¨ä¸Šä¸€è¡Œä»£ç çš„å°¾éƒ¨ï¼ŒæŒ‰ä¸‹Ctrl+D,å®ç°å¯¹ä¸Šä¸€è¡Œä»£ç çš„å¤åˆ¶
print("è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š{}".format(train_data.size))
# è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š10000

# åˆ©ç”¨DataLoaderæ¥åŠ è½½æ•°æ®é›†
train_dataLoader = DataLoder(train_data, batch_size=64)
test_datalaoder = DataLoder(test_data, batch_size=64)

# åˆ›å»ºç½‘è·¯æ¨¡å‹
tudui = Tudui()



# æŸå¤±å‡½æ•°
loss_fn = nn.CrossEntropyLoss()

# ä¼˜åŒ–å™¨
learning_rate = 0.01# æ–¹ä¾¿ä¿®æ”¹ï¼Œä¹Ÿå¯ä»¥å†™æˆ1e-2
optimizer = torch.optim.SGD(tudui.parameters(), lr=learning_rate, )

# è®¾ç½®è®­ç»ƒç½‘ç»œçš„ä¸€äº›å‚æ•°
total_train_step = 0	# è®°å½•è®­ç»ƒæ¬¡æ•°
total_test_step = 0		# è®°å½•æµ‹è¯•æ¬¡æ•°
epoch = 10		# è®­ç»ƒæ¬¡æ•°

# æ·»åŠ tensorboard
writer = SummaryWriter("./logs_train")

for i in range(epoch):
    print("------------------ç¬¬ {} è½®è®­ç»ƒå¼€å§‹-----------------".format(i+1))
    # è®­ç»ƒæ­¥éª¤å¼€å§‹
    tudui.train()
		# è®¾ç½®æ¨¡å‹è¿›å…¥è®­ç»ƒæ¨¡å¼ï¼Œåªå¯¹ç‰¹å®šçš„æ¨¡å‹æœ‰ä½œç”¨ï¼Œæ¯”å¦‚Dropout, BatchNorm
    for data in train_dataLoader:
        imgs, targets = data
        outputs = tudui(imgs)
        loss = loss_fn(outputs, targets)
        # ä¼˜åŒ–å™¨ä¼˜åŒ–æ¨¡å‹
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_train_step = total_train_step + 1
        # ä¸è®©ä»–æ¯æ¬¡éƒ½æ‰“å°(é€¢100æ‰æ‰“å°)
        if total_traib_step % 100 == 0:
          print("è®­ç»ƒæ¬¡æ•°ï¼š{}ï¼ŒLoss:{}".format(total_train_step, loss.item()))
          
          writer.add_scalar("train_loss", loss.item(), total_train_step)
        
    # æµ‹è¯•æ­¥éª¤å¼€å§‹
    tudui.eval()
    # è®¾ç½®æ¨¡å‹è¿›å…¥éªŒè¯æ¨¡å¼ï¼Œåªå¯¹ç‰¹å®šçš„æ¨¡å‹æœ‰ä½œç”¨ï¼Œæ¯”å¦‚Dropout, BatchNorm
    total_test_loss = 0
    total_accuracy = 0
    with torch.no_grad():
      for data in test_dataloader:
        img,  targets = data
        outputs = tudui(imgs)
        loss = loss_fn(outputs)
        total_test_loss = total_test_loss + loss.item()
        accuracy = (outputs.argmax(1) == targets).sum()
        total_accuracy = total_accuracy + accuracy
    print("æ•´ä½“æµ‹è¯•é›†ä¸Šçš„Loss:{}".format(total_test_loss))
    print("æ•´ä½“æµ‹è¯•é›†ä¸Šçš„æ­£ç¡®ç‡:{}".format(total_accuracy / test_data.size))
    writer.add_scalar("test_loss", total_test_loss, total_test_step)
    writer.add_scalar("test_accuracy", total_accuracy / test_data.size, total_test_step)
    total_test_step = total_test_step +  1
    # ä¿å­˜æ¯ä¸€è½®è®­ç»ƒçš„æˆæœ
    torch.save(tudui, "tudui_{}.pth".format(i))
    print("æ¨¡å‹å·²ä¿å­˜")

writer.close()
      
        
```

åœ¨terminal ä¸­æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼Œè¾“å…¥tensorboard --logdir=logs_train,ç‚¹å‡»è¾“å‡ºçš„ç«¯å£ï¼Œåœ¨å¼¹å‡ºçš„ç½‘é¡µä¸­å¯ä»¥çœ‹åˆ°è¾“å‡ºç»“æœ

# 30-åˆ©ç”¨GPUè¿›è¡Œè®­ç»ƒ

åªéœ€è¦åœ¨åŸå§‹ä»£ç ä¸Šè¿›è¡Œå°å¹…åº¦ä¿®æ”¹ï¼Œæœ‰ä¸¤å¼ æ–¹æ³•

- æ–¹æ³•1ï¼šæ‰¾åˆ°ç½‘ç»œæ¨¡å‹ã€æ•°æ®(è¾“å…¥ & è¾“å‡ºã€æ ‡æ³¨)ã€æŸå¤±å‡½æ•°ï¼Œå¯¹å…¶è°ƒç”¨`.cuda()`
  - åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè„šæœ¬train_gpu_1.py

```python
# train.py
import torchvision
from torch.utils.datya import DataLoader
from torch import nn
from torch.utils.tensorboard import SummaryWriter
import time


# å‡†å¤‡æ•°æ®é›†
train_data = torchvision.datasets.CIFAR10(root="./dataset/CIFAR10", train=True, transform=torchvision.transforms.ToTensor(), download=True)
test_data = torchvision.datasets.CIFAR10(root="./dataset/CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
# è®­ç»ƒé›†æ²¡æœ‰cudaæ–¹æ³•ï¼Œåªæœ‰è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ•°æ®æ‰æœ‰cudaæ–¹æ³•
# æŸ¥çœ‹æ•°æ®é›†å¤§å°
train_data.size = len(train_data)
test_data.size = len(test_data)
print("è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š{}".format(train_data.size))
# è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š50000
# å°†å…‰æ ‡æ”¾åœ¨ä¸Šä¸€è¡Œä»£ç çš„å°¾éƒ¨ï¼ŒæŒ‰ä¸‹Ctrl+D,å®ç°å¯¹ä¸Šä¸€è¡Œä»£ç çš„å¤åˆ¶
print("è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š{}".format(train_data.size))
# è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š10000

# åˆ©ç”¨DataLoaderæ¥åŠ è½½æ•°æ®é›†
train_dataLoader = DataLoder(train_data, batch_size=64)
test_datalaoder = DataLoder(test_data, batch_size=64)

# åˆ›å»ºç½‘è·¯æ¨¡å‹
class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.model = nn.Sequential(
        	nn.Conv2d(3, 32, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 32, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Linear(64*4*4, 64),
            nn.Linear(64, 10),
        )
        
    def forward(self, x):
        x = self.model(x)
        return x
   
tudui = Tudui()
if torch.cuda.is_available():# åˆ¤æ–­cudaæ˜¯å¦å¯ç”¨(å¯ä»¥å®ç°åœ¨cpuå’Œgpuéƒ½å¯ä»¥è·‘)
	tudui = tudui.cuda()# ç½‘ç»œæ¨¡å‹è½¬ç§»åˆ°cudaä¸Šé¢


# æŸå¤±å‡½æ•°
loss_fn = nn.CrossEntropyLoss()
if torch.cuda.is_available():
	loss_fn = loss_fn.cuda()

# ä¼˜åŒ–å™¨
learning_rate = 0.01# æ–¹ä¾¿ä¿®æ”¹ï¼Œä¹Ÿå¯ä»¥å†™æˆ1e-2
optimizer = torch.optim.SGD(tudui.parameters(), lr=learning_rate, )
# ä¼˜åŒ–å™¨æ²¡æœ‰cudaæ–¹æ³•

# è®¾ç½®è®­ç»ƒç½‘ç»œçš„ä¸€äº›å‚æ•°
total_train_step = 0	# è®°å½•è®­ç»ƒæ¬¡æ•°
total_test_step = 0		# è®°å½•æµ‹è¯•æ¬¡æ•°
epoch = 10		# è®­ç»ƒæ¬¡æ•°

# æ·»åŠ tensorboard
writer = SummaryWriter("./logs_train")
start_time = time.time()# è®°å½•æ—¶é—´

for i in range(epoch):
    print("------------------ç¬¬ {} è½®è®­ç»ƒå¼€å§‹-----------------".format(i+1))
    # è®­ç»ƒæ­¥éª¤å¼€å§‹
    tudui.train()
		# è®¾ç½®æ¨¡å‹è¿›å…¥è®­ç»ƒæ¨¡å¼ï¼Œåªå¯¹ç‰¹å®šçš„æ¨¡å‹æœ‰ä½œç”¨ï¼Œæ¯”å¦‚Dropout, BatchNorm
    for data in train_dataLoader:
        imgs, targets = data
        if torch.cuda.is_available():
          img = imgs.cuda()
          target = targets.cuda()
        outputs = tudui(imgs)
        loss = loss_fn(outputs, targets)
        # ä¼˜åŒ–å™¨ä¼˜åŒ–æ¨¡å‹
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_train_step = total_train_step + 1
        # ä¸è®©ä»–æ¯æ¬¡éƒ½æ‰“å°(é€¢100æ‰æ‰“å°)
        if total_traib_step % 100 == 0:
          end_time = time.time()
          print(end_time - start_time)
          print("è®­ç»ƒæ¬¡æ•°ï¼š{}ï¼ŒLoss:{}".format(total_train_step, loss.item()))
          
          writer.add_scalar("train_loss", loss.item(), total_train_step)
        
    # æµ‹è¯•æ­¥éª¤å¼€å§‹
    tudui.eval()
    # è®¾ç½®æ¨¡å‹è¿›å…¥éªŒè¯æ¨¡å¼ï¼Œåªå¯¹ç‰¹å®šçš„æ¨¡å‹æœ‰ä½œç”¨ï¼Œæ¯”å¦‚Dropout, BatchNorm
    total_test_loss = 0
    total_accuracy = 0
    with torch.no_grad():
      for data in test_dataloader:
        imgs,  targets = data
        if torch.cuda.is_available():
          imgs = imgs.cuda()
          targets = targets.cuda()
        outputs = tudui(imgs)
        loss = loss_fn(outputs)
        total_test_loss = total_test_loss + loss.item()
        accuracy = (outputs.argmax(1) == targets).sum()
        total_accuracy = total_accuracy + accuracy
    print("æ•´ä½“æµ‹è¯•é›†ä¸Šçš„Loss:{}".format(total_test_loss))
    print("æ•´ä½“æµ‹è¯•é›†ä¸Šçš„æ­£ç¡®ç‡:{}".format(total_accuracy / test_data_size))
    writer.add_scalar("test_loss", total_test_loss, total_test_step)
    writer.add_scalar("test_accuracy", total_accuracy / test_data_size, total_test_step)
    total_test_step = total_test_step +  1
    # ä¿å­˜æ¯ä¸€è½®è®­ç»ƒçš„æˆæœ
    torch.save(tudui, "tudui_{}.pth".format(i))
    print("æ¨¡å‹å·²ä¿å­˜")

writer.close() 
        
```



- æ–¹æ³•2ï¼šæ‰¾åˆ°ç½‘ç»œæ¨¡å‹ã€æ•°æ®(è¾“å…¥ & è¾“å‡ºã€æ ‡æ³¨)ã€æŸå¤±å‡½æ•°ï¼Œå¯¹å…¶è°ƒç”¨`.to(device)`
- è¦å…ˆå®šä¹‰è®¾å¤‡ï¼š`Device = torch.device("cpu")` æˆ–è€…`Device = torch.device("cuda:0")`(æœ‰å¤šä¸ªæ˜¾å¡ï¼šcuda:x)
  - åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè„šæœ¬train_gpu_2.py

```python
# train.py
import torchvision
from torch.utils.datya import DataLoader
from torch import nn
from torch.utils.tensorboard import SummaryWriter
import time

# å®šä¹‰è®­ç»ƒè®¾å¤‡
device = torch.device("cpu")
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# å‡†å¤‡æ•°æ®é›†
train_data = torchvision.datasets.CIFAR10(root="./dataset/CIFAR10", train=True, transform=torchvision.transforms.ToTensor(), download=True)
test_data = torchvision.datasets.CIFAR10(root="./dataset/CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
# è®­ç»ƒé›†æ²¡æœ‰cudaæ–¹æ³•ï¼Œåªæœ‰è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ•°æ®æ‰æœ‰cudaæ–¹æ³•
# æŸ¥çœ‹æ•°æ®é›†å¤§å°
train_data.size = len(train_data)
test_data.size = len(test_data)
print("è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š{}".format(train_data.size))
# è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š50000
# å°†å…‰æ ‡æ”¾åœ¨ä¸Šä¸€è¡Œä»£ç çš„å°¾éƒ¨ï¼ŒæŒ‰ä¸‹Ctrl+D,å®ç°å¯¹ä¸Šä¸€è¡Œä»£ç çš„å¤åˆ¶
print("è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š{}".format(train_data.size))
# è®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ä¸ºï¼š10000

# åˆ©ç”¨DataLoaderæ¥åŠ è½½æ•°æ®é›†
train_dataLoader = DataLoder(train_data, batch_size=64)
test_datalaoder = DataLoder(test_data, batch_size=64)

# åˆ›å»ºç½‘è·¯æ¨¡å‹
class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.model = nn.Sequential(
        	nn.Conv2d(3, 32, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 32, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Linear(64*4*4, 64),
            nn.Linear(64, 10),
        )
        
    def forward(self, x):
        x = self.model(x)
        return x
   
tudui = Tudui()
tudui = tudui.to(device)


# æŸå¤±å‡½æ•°
loss_fn = nn.CrossEntropyLoss()
loss_fn = loss_fn.to(device)

# ä¼˜åŒ–å™¨
learning_rate = 0.01# æ–¹ä¾¿ä¿®æ”¹ï¼Œä¹Ÿå¯ä»¥å†™æˆ1e-2
optimizer = torch.optim.SGD(tudui.parameters(), lr=learning_rate, )
# ä¼˜åŒ–å™¨æ²¡æœ‰cudaæ–¹æ³•

# è®¾ç½®è®­ç»ƒç½‘ç»œçš„ä¸€äº›å‚æ•°
total_train_step = 0	# è®°å½•è®­ç»ƒæ¬¡æ•°
total_test_step = 0		# è®°å½•æµ‹è¯•æ¬¡æ•°
epoch = 10		# è®­ç»ƒæ¬¡æ•°

# æ·»åŠ tensorboard
writer = SummaryWriter("./logs_train")
start_time = time.time()# è®°å½•æ—¶é—´

for i in range(epoch):
    print("------------------ç¬¬ {} è½®è®­ç»ƒå¼€å§‹-----------------".format(i+1))
    # è®­ç»ƒæ­¥éª¤å¼€å§‹
    tudui.train()
		# è®¾ç½®æ¨¡å‹è¿›å…¥è®­ç»ƒæ¨¡å¼ï¼Œåªå¯¹ç‰¹å®šçš„æ¨¡å‹æœ‰ä½œç”¨ï¼Œæ¯”å¦‚Dropout, BatchNorm
    for data in train_dataLoader:
        imgs, targets = data
        imgs = imgs.to(device)
        targets = targets.to(device)
        outputs = tudui(imgs)
        loss = loss_fn(outputs, targets)
        # ä¼˜åŒ–å™¨ä¼˜åŒ–æ¨¡å‹
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_train_step = total_train_step + 1
        # ä¸è®©ä»–æ¯æ¬¡éƒ½æ‰“å°(é€¢100æ‰æ‰“å°)
        if total_traib_step % 100 == 0:
          end_time = time.time()
          print(end_time - start_time)
          print("è®­ç»ƒæ¬¡æ•°ï¼š{}ï¼ŒLoss:{}".format(total_train_step, loss.item()))
          
          writer.add_scalar("train_loss", loss.item(), total_train_step)
        
    # æµ‹è¯•æ­¥éª¤å¼€å§‹
    tudui.eval()
    # è®¾ç½®æ¨¡å‹è¿›å…¥éªŒè¯æ¨¡å¼ï¼Œåªå¯¹ç‰¹å®šçš„æ¨¡å‹æœ‰ä½œç”¨ï¼Œæ¯”å¦‚Dropout, BatchNorm
    total_test_loss = 0
    total_accuracy = 0
    with torch.no_grad():
      for data in test_dataloader:
        imgs,  targets = data
        imgs = imgs.to(device)
        targets = targets.to(device)
        outputs = tudui(imgs)
        loss = loss_fn(outputs)
        total_test_loss = total_test_loss + loss.item()
        accuracy = (outputs.argmax(1) == targets).sum()
        total_accuracy = total_accuracy + accuracy
    print("æ•´ä½“æµ‹è¯•é›†ä¸Šçš„Loss:{}".format(total_test_loss))
    print("æ•´ä½“æµ‹è¯•é›†ä¸Šçš„æ­£ç¡®ç‡:{}".format(total_accuracy / test_data_size))
    writer.add_scalar("test_loss", total_test_loss, total_test_step)
    writer.add_scalar("test_accuracy", total_accuracy / test_data_size, total_test_step)
    total_test_step = total_test_step +  1
    # ä¿å­˜æ¯ä¸€è½®è®­ç»ƒçš„æˆæœ
    torch.save(tudui, "tudui_{}.pth".format(i))
    print("æ¨¡å‹å·²ä¿å­˜")

writer.close() 
        
```

# 32-å®Œæ•´çš„æ¨¡å‹éªŒè¯å¥—è·¯

åˆ©ç”¨å·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹ç»™ä»–æä¾›è¾“å…¥

åœ¨pycharmé¡¹ç›®ä¸‹æ–°å»ºpythonè„šæœ¬test.pyï¼Œå…ˆä»ç½‘ç«™ä¸Šdownloadä¸€å¼ ç‹—çš„ç…§ç‰‡æ”¾åœ¨imgsæ–‡ä»¶å¤¹é‡Œ

![image-20251101164331743](https://typora-alex2.oss-cn-shanghai.aliyuncs.com/202511011643783.png)

```python
from PIL import Image

image_path = " ./imgs/dog.png"
image = Image.open(image_path)
print(image)
# PIL.Png ç±»å‹
image = image.convert("RGB")
# å› ä¸ºpngæ ¼å¼æ˜¯å››é€šé“ï¼Œé™¤äº†RGBé€šé“ä»¥å¤–ï¼Œè¿˜æœ‰é€æ˜åº¦é€šé“RGBA(Alpha)
# å¦‚æœå›¾ç‰‡æœ¬æ¥å°±æ˜¯ä¸‰ä¸ªé¢œè‰²é€šé“ï¼Œç»è¿‡æ­¤æ“ä½œä¸å˜

transform = torchvision.transforms.Compose(
  [torchvision.transforms.Resize((32, 32)),
   torchvision.transforms.ToTensor()]
  # Resize:è¾“å…¥æ˜¯Tensorè¿”å›ä¹Ÿæ˜¯Tensorï¼Œè¾“å…¥ä¸ºImageè¿”å›ä¹Ÿæ˜¯Image
)
image = transform(image)
print(image.shape)
# torch.Size([3, 32, 32])

# åˆ›å»ºç½‘è·¯æ¨¡å‹
class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        self.model = nn.Sequential(
        	nn.Conv2d(3, 32, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 32, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 5, 1, 2),
            nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Linear(64*4*4, 64),
            nn.Linear(64, 10),
        )
        
    def forward(self, x):
        x = self.model(x)
        return x
      
# åŠ è½½ç½‘ç»œæ¨¡å‹
model = torch.load("tudui_0.pth", map_location=torch.device("cpu"),  weights_only=False)
print(model)
image = torch.reshape(image, (1, 3, 32, 32))
model.eval()
with torch.no_grad():# èŠ‚çœæ—¶é—´å’Œå†…å­˜
	output = model(image)
print(output)
# tensor([[-1.7778, -0.1296, 0.5985, 0.7647, 0.7575, 0.9315, 1.0523ï¼Œ0.5670, -2.2151, -0.9987]])
# é¢„æµ‹ç»“æœä¸ºç¬¬6ä¸ªclasss(1.0523å€¼æœ€å¤§)
print(output.argmax(1))
#  tensor([6])
# ä¸»è¦ç”±äºè®­ç»ƒè½®æ•°å¤ªå°‘ï¼Œåªæœ‰1è½®
```

![image-20251101170648344](https://typora-alex2.oss-cn-shanghai.aliyuncs.com/202511011706385.png)

![image-20251101172447339](https://typora-alex2.oss-cn-shanghai.aliyuncs.com/202511011724381.png)



