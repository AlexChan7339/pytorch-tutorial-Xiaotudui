# 23-损失函数与反向传播

> 有一张试卷，题型：选择（30%），填空（20%）， 解答（50%），满分100（target），实际上只考了30分：选择（10‘），填空（10‘）， 解答（10‘），损失函数衡量实际与目标（target）之间的差距，这边就是$Loss=(30-10)+(20-10)+(50-10)=70$, 差距可以知道损失函数（解答部分太弱了，多训练解答部分）去接近target，损失函数大多数情况下越小越好

损失函数作用：

1. 计算实际输出和目标之间的差距；
2. 为我们更新输出提供一定依据（反向传播）,为每一个卷积核参数（需要调整的uix）提供梯度参数，进而降低loss，类似梯度下降法

![image-20251029210715675](https://typora3.oss-cn-shanghai.aliyuncs.com/202511062104200.png)

- nn.L1Loss:计算输出与其对应输出的差值绝对值之和（也可以求平均）

  ![image-20251029210833343](https://typora3.oss-cn-shanghai.aliyuncs.com/202511062104460.png)

  - 注意输入和输出的shape

    ![image-20251029210949850](https://typora3.oss-cn-shanghai.aliyuncs.com/202511062104091.png)

    - N：batch_size

在pycharm项目下新建python脚本nn_loss

## L1LOSS

```python
import torch
from torch.nn import L1Loss

inputs = torch.tensor([1, 2, 3])
targets = torch.tensor([1, 2, 5])

inputs = torch.reshape(inputs, (1, 1, 1, 3))
targets = torch.reshape(targets, (1, 1, 1, 3))

loss = L1Loss()
result = Loss(inputs, targets)

print(result)
# 会报错：RuntimeError: Can only calculate the mean of floating types. Got Long instead.
```

```python
import torch
from torch.nn import L1Loss

inputs = torch.tensor([1, 2, 3], dtype=torch.float32)
targets = torch.tensor([1, 2, 5], dtype=torch.float32)

inputs = torch.reshape(inputs, (1, 1, 1, 3))
targets = torch.reshape(targets, (1, 1, 1, 3))

loss = L1Loss()
result = Loss(inputs, targets)

print(result)
# tensor(0.6667)
```

```python
# 设置reduction参数
import torch
from torch.nn import L1Loss

inputs = torch.tensor([1, 2, 3], dtype=torch.float32)
targets = torch.tensor([1, 2, 5], dtype=torch.float32)

inputs = torch.reshape(inputs, (1, 1, 1, 3))
targets = torch.reshape(targets, (1, 1, 1, 3))

loss = L1Loss(reduction='sum')
result = Loss(inputs, targets)

print(result)
# tensor(2.)
```

## 均方误差

![image-20251029211906931](https://typora3.oss-cn-shanghai.aliyuncs.com/202511062104255.png)

![image-20251029211916849](https://typora3.oss-cn-shanghai.aliyuncs.com/202511062104485.png)

```python
import torch
from torch import nn

inputs = torch.tensor([1, 2, 3], dtype=torch.float32)
targets = torch.tensor([1, 2, 5], dtype=torch.float32)

inputs = torch.reshape(inputs, (1, 1, 1, 3))
targets = torch.reshape(targets, (1, 1, 1, 3))

loss_mse = nn.MSELoss()
result_mse = loss_mse(inputs, targets)

print(result_mse)
```

## 交叉熵损失函数

适用于分类问题（多分类& 双分类）

![image-20251029220556370](https://typora3.oss-cn-shanghai.aliyuncs.com/202511062104585.png)

![image-20251029222356580](https://typora3.oss-cn-shanghai.aliyuncs.com/202511062104610.png)

- C:类别数

---

有一个三分类问题：Person， dog, cat,现在有一种狗的图片，还有一个神经网络，会输出一个概率【0.1， 0.2， 0.3】（交叉熵中概率和不一定等于1，概率可以看成下下图神经网络输出结果，这边$y_i=1$），计算loss

![image-20251029221053971](https://typora3.oss-cn-shanghai.aliyuncs.com/202511062104928.png)

![image-20251029221857212](https://typora3.oss-cn-shanghai.aliyuncs.com/202511062104030.png)

![image-20251029221907256](https://typora3.oss-cn-shanghai.aliyuncs.com/202511062104145.png)

```python
from torch import nn

x = torch.tensor([0.1, 0.2, 0.3])# 神经网络输出值
y = torch.tensor([1])# 下个例子中target值
x = torch.reshape(x, (1, 3))
loss_cross = nn.CrossEntropyLoss()
result_cross = loss_cross(x, y)
print(result_cross)
# tensor(1.1019)

```

在pycharm项目下新建python脚本nn_loss_network

```python
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential, Flatten, Linear
from torchvision import SummaryWriter

dataset = torchvision.datasets.CIFAR10("./data.CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=1)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        
        self.modle1 = Sequential(
            Conv2d(3, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        		
        )
    
    def forward(self, x):
        x = self.model1(x)
        return x
    
tudui = Tudui()
for data in dataloader:
    img, targets = data
    ouutputs = tudui(imgs)
    print(outputs)
    print(targets)
    
```

![image-20251029224433632](https://typora3.oss-cn-shanghai.aliyuncs.com/202511062104071.png)

```python
# 加入叫交叉熵损失
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential, Flatten, Linear
from torchvision import SummaryWriter

dataset = torchvision.datasets.CIFAR10("./data.CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=1)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        
        self.modle1 = Sequential(
            Conv2d(3, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        		
        )
    
    def forward(self, x):
        x = self.model1(x)
        return x

loss = nn.CrossEntrophyLoss()
tudui = Tudui()
for data in dataloader:
    img, targets = data
    ouutputs = tudui(imgs)
    result_loss = loss(outputs, targets)
    
```

反向传播：为每一个卷积核参数（需要调整的对象）提供梯度参数，进而降低loss，类似梯度下降法

```python
# 加入反向传播
import torchvision
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential, Flatten, Linear
from torchvision import SummaryWriter
from torch.utils.data import DataLoader

dataset = torchvision.datasets.CIFAR10("./data.CIFAR10", train=False, transform=torchvision.transforms.ToTensor(), download=True)
dataloader = DataLoader(dataset, batch_size=1)

class Tudui(nn.Module):
    def __init__(self):
        super(Tudui, self).__init__()
        
        self.modle1 = Sequential(
            Conv2d(3, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 32, 5, padding=2),
            MaxPool2d(2),
            Conv2d(32, 64, 5, padding=2),
            MaxPool2d(2),
            Flatten(),
            Linear(1024, 64),
            Linear(64, 10)
        		
        )
    
    def forward(self, x):
        x = self.model1(x)
        return x

loss = nn.CrossEntrophyLoss()
tudui = Tudui()
for data in dataloader:
    img, targets = data
    ouutputs = tudui(imgs)
    result_loss = loss(outputs, targets)
    result_loss.backward()
    print("ok")
    # 可以dubug查看变量列表下tudui--model1--Protected Attributes--_modules--'0'--weight--grad
    # weight下拉中的data是指weight值
    # 一开始grad的值应该为None
    # 每一次运行都会对grad值进行更新
    # 如果没有result_loss.backward()，则不会对grad进行更新
```
